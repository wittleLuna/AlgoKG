"""
æ¨¡æ‹Ÿé—®ç­”ç³»ç»Ÿæ¨¡å—
å½“åŸå§‹é—®ç­”ç³»ç»Ÿä¸å¯ç”¨æ—¶ä½¿ç”¨æ­¤æ¨¡å—
"""

import asyncio
import json
import random
from typing import Dict, Any, List, Optional
from datetime import datetime

class MockQwenClient:
    """æ¨¡æ‹ŸQwenå®¢æˆ·ç«¯"""

    def __init__(self, api_key=None):
        self.api_key = api_key or "mock_key"
    
    def generate_response(self, prompt: str) -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿå“åº”"""
        if "åŠ¨æ€è§„åˆ’" in prompt:
            return "åŠ¨æ€è§„åˆ’æ˜¯ä¸€ç§ç®—æ³•è®¾è®¡æŠ€æœ¯ï¼Œé€šè¿‡å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºå­é—®é¢˜æ¥è§£å†³ã€‚"
        elif "äºŒå‰æ ‘" in prompt:
            return "äºŒå‰æ ‘æ˜¯ä¸€ç§æ ‘å½¢æ•°æ®ç»“æ„ï¼Œæ¯ä¸ªèŠ‚ç‚¹æœ€å¤šæœ‰ä¸¤ä¸ªå­èŠ‚ç‚¹ã€‚"
        elif "æ’åº" in prompt:
            return "æ’åºç®—æ³•ç”¨äºå°†æ•°æ®æŒ‰ç‰¹å®šé¡ºåºæ’åˆ—ï¼Œå¸¸è§çš„æœ‰å¿«é€Ÿæ’åºã€å½’å¹¶æ’åºç­‰ã€‚"
        else:
            return f"è¿™æ˜¯å…³äº'{prompt}'çš„æ¨¡æ‹Ÿå›ç­”ã€‚åœ¨å®é™…ç¯å¢ƒä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨çœŸæ­£çš„AIæ¨¡å‹ã€‚"

class MockNeo4jKnowledgeGraphAPI:
    """æ¨¡æ‹ŸNeo4jçŸ¥è¯†å›¾è°±API"""
    
    def __init__(self, uri: str, user: str, password: str):
        self.uri = uri
        self.user = user
        self.password = password
        self.driver = None
    
    def get_problem_by_title(self, title: str) -> Optional[Dict[str, Any]]:
        """æ¨¡æ‹Ÿè·å–é¢˜ç›®ä¿¡æ¯"""
        return {
            "title": title,
            "difficulty": "ä¸­ç­‰",
            "platform": "LeetCode",
            "category": "åŠ¨æ€è§„åˆ’",
            "algorithms": [{"name": "åŠ¨æ€è§„åˆ’"}],
            "data_structures": [{"name": "æ•°ç»„"}],
            "techniques": [{"name": "çŠ¶æ€è½¬ç§»"}]
        }
    
    def get_similar_problems(self, title: str, limit: int = 5) -> List[Dict[str, Any]]:
        """æ¨¡æ‹Ÿè·å–ç›¸ä¼¼é¢˜ç›®"""
        similar_titles = [
            "çˆ¬æ¥¼æ¢¯",
            "æ–æ³¢é‚£å¥‘æ•°åˆ—",
            "æœ€é•¿é€’å¢å­åºåˆ—",
            "èƒŒåŒ…é—®é¢˜",
            "æœ€å¤§å­æ•°ç»„å’Œ"
        ]
        
        return [
            {
                "title": similar_title,
                "difficulty": random.choice(["ç®€å•", "ä¸­ç­‰", "å›°éš¾"]),
                "category": "åŠ¨æ€è§„åˆ’",
                "similarity_score": random.uniform(0.6, 0.9)
            }
            for similar_title in similar_titles[:limit]
        ]
    
    def get_algorithm_by_name(self, name: str) -> Optional[Dict[str, Any]]:
        """æ¨¡æ‹Ÿè·å–ç®—æ³•ä¿¡æ¯"""
        return {
            "algorithm": {
                "name": name,
                "description": f"{name}çš„æè¿°",
                "time_complexity": "O(n)",
                "space_complexity": "O(1)"
            },
            "problems": self.get_similar_problems(name, 3)
        }

    def get_node_by_name(self, name: str) -> Optional[Dict[str, Any]]:
        """æ¨¡æ‹Ÿé€šç”¨èŠ‚ç‚¹æŸ¥è¯¢"""
        # æ¨¡æ‹Ÿä¸åŒç±»å‹çš„èŠ‚ç‚¹
        if "é“¾è¡¨" in name or "èŠ‚ç‚¹" in name or "ä¸¤ä¸¤äº¤æ¢" in name:
            return {
                "node": {"title": name, "description": f"å…³äº{name}çš„é¢˜ç›®"},
                "type": "Problem",
                "labels": ["Problem"],
                "name": name,
                "title": name
            }
        elif "ç®—æ³•" in name or "æ’åº" in name or "æœç´¢" in name:
            return {
                "node": {"name": name, "description": f"{name}ç®—æ³•"},
                "type": "Algorithm",
                "labels": ["Algorithm"],
                "name": name,
                "title": name
            }
        elif "äºŒå‰æ ‘" in name or "é“¾è¡¨" in name:
            return {
                "node": {"name": name, "description": f"{name}æ•°æ®ç»“æ„"},
                "type": "DataStructure",
                "labels": ["DataStructure"],
                "name": name,
                "title": name
            }
        else:
            return None
    
    def get_data_structure_by_name(self, name: str) -> Optional[Dict[str, Any]]:
        """æ¨¡æ‹Ÿè·å–æ•°æ®ç»“æ„ä¿¡æ¯"""
        return {
            "data_structure": {
                "name": name,
                "description": f"{name}çš„æè¿°",
                "operations": ["æ’å…¥", "åˆ é™¤", "æŸ¥æ‰¾"]
            },
            "problems": self.get_similar_problems(name, 3)
        }
    
    def get_technique_by_name(self, name: str) -> Optional[Dict[str, Any]]:
        """æ¨¡æ‹Ÿè·å–æŠ€å·§ä¿¡æ¯"""
        return {
            "technique": {
                "name": name,
                "description": f"{name}çš„æè¿°",
                "applications": ["åœºæ™¯1", "åœºæ™¯2"]
            },
            "problems": self.get_similar_problems(name, 3)
        }
    
    def get_statistics(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿè·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_problems": 150,
            "total_algorithms": 25,
            "total_data_structures": 15,
            "difficulty_distribution": [
                {"difficulty": "ç®€å•", "count": 50},
                {"difficulty": "ä¸­ç­‰", "count": 70},
                {"difficulty": "å›°éš¾", "count": 30}
            ],
            "top_categories": [
                {"category": "åŠ¨æ€è§„åˆ’", "count": 30},
                {"category": "æ ‘", "count": 25},
                {"category": "å›¾", "count": 20}
            ]
        }

class MockEnhancedRecommendationSystem:
    """æ¨¡æ‹Ÿæ¨èç³»ç»Ÿ"""

    def __init__(self, **kwargs):
        self.config = kwargs
        print("ğŸ”„ æ¨¡æ‹Ÿæ¨èç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def recommend(self, query_title: str, top_k: int = 10, alpha: float = 0.7,
                 enable_diversity: bool = True, diversity_lambda: float = 0.3) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæ¨èæ–¹æ³• - ä¸çœŸå®æ¨èç³»ç»Ÿæ¥å£ä¿æŒä¸€è‡´"""
        try:
            # æ¨¡æ‹Ÿä¸€äº›å¸¸è§çš„ç®—æ³•é¢˜ç›®
            mock_problems = [
                "ä¸¤æ•°ä¹‹å’Œ", "ä¸‰æ•°ä¹‹å’Œ", "å››æ•°ä¹‹å’Œ", "æœ€é•¿å…¬å…±å­åºåˆ—", "æœ€é•¿é€’å¢å­åºåˆ—",
                "çˆ¬æ¥¼æ¢¯", "æ–æ³¢é‚£å¥‘æ•°åˆ—", "é›¶é’±å…‘æ¢", "èƒŒåŒ…é—®é¢˜", "æœ€çŸ­è·¯å¾„",
                "äºŒåˆ†æŸ¥æ‰¾", "å¿«é€Ÿæ’åº", "å½’å¹¶æ’åº", "å †æ’åº", "æ‹“æ‰‘æ’åº",
                "æ·±åº¦ä¼˜å…ˆæœç´¢", "å¹¿åº¦ä¼˜å…ˆæœç´¢", "åŠ¨æ€è§„åˆ’å…¥é—¨", "è´ªå¿ƒç®—æ³•", "åˆ†æ²»ç®—æ³•"
            ]

            # ç”Ÿæˆæ¨èç»“æœ
            recommendations = []
            for i in range(min(top_k, len(mock_problems))):
                problem_title = mock_problems[i]
                if problem_title == query_title:
                    continue

                recommendations.append({
                    "title": problem_title,
                    "hybrid_score": round(random.uniform(0.7, 0.95), 4),
                    "embedding_score": round(random.uniform(0.6, 0.9), 4),
                    "tag_score": round(random.uniform(0.5, 0.8), 4),
                    "shared_tags": random.sample(["åŠ¨æ€è§„åˆ’", "æ•°ç»„", "å“ˆå¸Œè¡¨", "åŒæŒ‡é’ˆ", "è´ªå¿ƒ"],
                                                random.randint(1, 3)),
                    "learning_path": {
                        "difficulty_progression": "ç®€å• â†’ ä¸­ç­‰",
                        "concept_chain": ["åŸºç¡€æ¦‚å¿µ", "ç®—æ³•æ€è·¯", "ä»£ç å®ç°"],
                        "estimated_time": f"{random.randint(30, 120)}åˆ†é’Ÿ"
                    },
                    "recommendation_reason": f"ä¸ã€Š{query_title}ã€‹åœ¨ç®—æ³•æ€è·¯ä¸Šç›¸ä¼¼ï¼Œé€‚åˆè¿›é˜¶å­¦ä¹ "
                })

            return {
                "status": "success",
                "query_title": query_title,
                "algorithm_analysis": {
                    "primary_algorithm": "åŠ¨æ€è§„åˆ’",
                    "complexity_analysis": "æ—¶é—´å¤æ‚åº¦O(n)ï¼Œç©ºé—´å¤æ‚åº¦O(n)",
                    "key_concepts": ["çŠ¶æ€è½¬ç§»", "æœ€ä¼˜å­ç»“æ„"]
                },
                "recommendations": recommendations,
                "total_candidates": len(recommendations),
                "recommendation_strategy": {
                    "embedding_weight": alpha,
                    "diversity_enabled": enable_diversity,
                    "diversity_weight": diversity_lambda
                }
            }

        except Exception as e:
            print(f"æ¨¡æ‹Ÿæ¨èç³»ç»Ÿé”™è¯¯: {e}")
            return {
                "status": "error",
                "error": str(e),
                "recommendations": []
            }

    def find_similar_problems(self, problem_title: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """æ¨¡æ‹ŸæŸ¥æ‰¾ç›¸ä¼¼é¢˜ç›®"""
        similar_problems = [
            {
                "title": f"ç›¸ä¼¼é¢˜ç›®{i+1}",
                "hybrid_score": random.uniform(0.7, 0.95),
                "similarity_analysis": {
                    "embedding_similarity": random.uniform(0.6, 0.9),
                    "tag_similarity": random.uniform(0.5, 0.8),
                    "shared_concepts": ["åŠ¨æ€è§„åˆ’", "æ•°ç»„"]
                },
                "learning_path": {
                    "path_description": f"å­¦ä¹ è·¯å¾„{i+1}",
                    "reasoning": f"æ¨èç†ç”±{i+1}"
                },
                "recommendation_reason": f"å› ä¸ºä¸{problem_title}åœ¨ç®—æ³•æ€è·¯ä¸Šç›¸ä¼¼",
                "recommendation_strength": "å¼ºæ¨è" if i < 2 else "æ¨è",
                "complete_info": {
                    "id": f"problem_{i+1}",
                    "title": f"ç›¸ä¼¼é¢˜ç›®{i+1}",
                    "difficulty": random.choice(["ç®€å•", "ä¸­ç­‰", "å›°éš¾"]),
                    "platform": "LeetCode",
                    "algorithm_tags": ["åŠ¨æ€è§„åˆ’"],
                    "data_structure_tags": ["æ•°ç»„"],
                    "technique_tags": ["çŠ¶æ€è½¬ç§»"]
                }
            }
            for i in range(top_k)
        ]
        return similar_problems

class MockGraphEnhancedMultiAgentSystem:
    """æ¨¡æ‹Ÿå¤šæ™ºèƒ½ä½“é—®ç­”ç³»ç»Ÿ"""

    def __init__(self, rec_system=None, neo4j_api=None, entity_id_to_title_path=None, qwen_client=None, **kwargs):
        # å¿½ç•¥æ‰€æœ‰å¯èƒ½å¯¼è‡´åˆå§‹åŒ–å¤±è´¥çš„å‚æ•°
        self.rec_system = rec_system or MockEnhancedRecommendationSystem()
        self.neo4j_api = neo4j_api or MockNeo4jKnowledgeGraphAPI("", "", "")
        self.qwen_client = qwen_client or MockQwenClient()
        self.similar_problem_finder = self
        self.entity_id_to_title_path = entity_id_to_title_path
        print("ğŸ”„ æ¨¡æ‹Ÿå¤šæ™ºèƒ½ä½“é—®ç­”ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    async def process_query(self, query: str) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿå¤„ç†æŸ¥è¯¢"""
        # ç”Ÿæˆå®æ—¶æ¨ç†è·¯å¾„
        reasoning_path = []

        # æ­¥éª¤1: åˆ†ææŸ¥è¯¢
        step_start = datetime.now()
        reasoning_path.append({
            "agent_name": "analyzer",
            "step_type": "analysis",
            "description": "åˆ†ææŸ¥è¯¢æ„å›¾å’Œå…³é”®å®ä½“",
            "status": "processing",
            "start_time": step_start.isoformat(),
            "end_time": None,
            "confidence": None,
            "result": {}
        })

        # æ¨¡æ‹Ÿåˆ†ææ—¶é—´
        await asyncio.sleep(0.3)
        entities = self._extract_entities(query)

        step_end = datetime.now()
        reasoning_path[0].update({
            "status": "success",
            "end_time": step_end.isoformat(),
            "confidence": 0.92,
            "result": {
                "intent": "concept_explanation",
                "entities": entities,
                "difficulty": "ä¸­ç­‰"
            }
        })

        # æ­¥éª¤2: çŸ¥è¯†æ£€ç´¢
        step_start = datetime.now()
        reasoning_path.append({
            "agent_name": "knowledge_retriever",
            "step_type": "retrieval",
            "description": "ä»çŸ¥è¯†å›¾è°±æ£€ç´¢ç›¸å…³ä¿¡æ¯",
            "status": "processing",
            "start_time": step_start.isoformat(),
            "end_time": None,
            "confidence": None,
            "result": {}
        })

        # æ¨¡æ‹Ÿæ£€ç´¢æ—¶é—´
        await asyncio.sleep(0.4)

        step_end = datetime.now()
        reasoning_path[1].update({
            "status": "success",
            "end_time": step_end.isoformat(),
            "confidence": 0.88,
            "result": {
                "count": 15,
                "sources": ["çŸ¥è¯†å›¾è°±", "é¢˜ç›®åº“"],
                "concepts_found": entities
            }
        })

        # æ­¥éª¤3: æ¦‚å¿µè§£é‡Š
        step_start = datetime.now()
        reasoning_path.append({
            "agent_name": "concept_explainer",
            "step_type": "explanation",
            "description": "ç”Ÿæˆæ¦‚å¿µè§£é‡Šå’Œç¤ºä¾‹",
            "status": "processing",
            "start_time": step_start.isoformat(),
            "end_time": None,
            "confidence": None,
            "result": {}
        })

        # æ¨¡æ‹Ÿè§£é‡Šæ—¶é—´
        await asyncio.sleep(0.5)
        concept_explanation = self._generate_concept_explanation(entities[0] if entities else "ç®—æ³•")
        example_problems = self._generate_example_problems()

        step_end = datetime.now()
        reasoning_path[2].update({
            "status": "success",
            "end_time": step_end.isoformat(),
            "confidence": 0.90,
            "result": {
                "concepts": entities,
                "examples_generated": len(example_problems),
                "explanation_sections": ["å®šä¹‰", "åŸç†", "åº”ç”¨"]
            }
        })

        # æ­¥éª¤4: æ•´åˆå›ç­”
        step_start = datetime.now()
        reasoning_path.append({
            "agent_name": "integrator",
            "step_type": "integration",
            "description": "æ•´åˆæ‰€æœ‰ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆå›ç­”",
            "status": "processing",
            "start_time": step_start.isoformat(),
            "end_time": None,
            "confidence": None,
            "result": {}
        })

        # æ¨¡æ‹Ÿæ•´åˆæ—¶é—´
        await asyncio.sleep(0.3)
        similar_problems = self._generate_similar_problems()
        integrated_response = self._generate_integrated_response(query)

        step_end = datetime.now()
        reasoning_path[3].update({
            "status": "success",
            "end_time": step_end.isoformat(),
            "confidence": 0.94,
            "result": {
                "sections": ["æ¦‚å¿µè§£é‡Š", "ç¤ºä¾‹é¢˜ç›®", "ç›¸ä¼¼æ¨è"],
                "final_confidence": 0.91,
                "response_length": len(integrated_response)
            }
        })

        result = {
            "intent": "concept_explanation",
            "entities": entities,
            "concept_explanation": concept_explanation,
            "example_problems": example_problems,
            "similar_problems": similar_problems,
            "integrated_response": integrated_response,
            "graph_data": self._generate_graph_data(entities),
            "reasoning_path": reasoning_path,
            "metadata": {
                "confidence": 0.91,
                "processing_time": sum([
                    (datetime.fromisoformat(step["end_time"]) - datetime.fromisoformat(step["start_time"])).total_seconds() * 1000
                    for step in reasoning_path if step["end_time"]
                ])
            }
        }

        # è°ƒè¯•ä¿¡æ¯
        print(f"ç”Ÿæˆçš„æ¨ç†è·¯å¾„: {len(reasoning_path)} ä¸ªæ­¥éª¤")
        for i, step in enumerate(reasoning_path):
            print(f"æ­¥éª¤ {i+1}: {step['agent_name']} - {step['description']} - {step['status']}")

        return result
    
    def _extract_entities(self, query: str) -> List[str]:
        """æå–å®ä½“"""
        entities = []
        keywords = ["åŠ¨æ€è§„åˆ’", "äºŒå‰æ ‘", "æ’åº", "å›¾", "æ•°ç»„", "é“¾è¡¨", "æ ˆ", "é˜Ÿåˆ—"]
        for keyword in keywords:
            if keyword in query:
                entities.append(keyword)
        return entities or ["ç®—æ³•"]
    
    def _generate_concept_explanation(self, concept: str) -> Dict[str, Any]:
        """ç”Ÿæˆæ¦‚å¿µè§£é‡Š"""
        return {
            "concept_name": concept,
            "definition": f"{concept}æ˜¯ä¸€ç§é‡è¦çš„ç®—æ³•/æ•°æ®ç»“æ„æ¦‚å¿µã€‚",
            "core_principles": [
                f"{concept}çš„æ ¸å¿ƒåŸç†1",
                f"{concept}çš„æ ¸å¿ƒåŸç†2",
                f"{concept}çš„æ ¸å¿ƒåŸç†3"
            ],
            "when_to_use": f"å½“éœ€è¦{concept}ç›¸å…³æ“ä½œæ—¶ä½¿ç”¨",
            "advantages": [f"{concept}çš„ä¼˜ç‚¹1", f"{concept}çš„ä¼˜ç‚¹2"],
            "disadvantages": [f"{concept}çš„ç¼ºç‚¹1"],
            "implementation_key_points": [
                f"{concept}å®ç°è¦ç‚¹1",
                f"{concept}å®ç°è¦ç‚¹2"
            ],
            "common_variations": [f"{concept}å˜ç§1", f"{concept}å˜ç§2"],
            "real_world_applications": [f"{concept}åº”ç”¨åœºæ™¯1", f"{concept}åº”ç”¨åœºæ™¯2"],
            "learning_progression": {
                "prerequisites": ["åŸºç¡€æ•°å­¦", "ç¼–ç¨‹åŸºç¡€"],
                "next_concepts": [f"é«˜çº§{concept}", f"{concept}ä¼˜åŒ–"]
            },
            "visual_explanation": f"{concept}çš„å¯è§†åŒ–è§£é‡Š",
            "clickable_concepts": ["åŸºç¡€æ•°å­¦", "ç¼–ç¨‹åŸºç¡€", f"é«˜çº§{concept}"]
        }
    
    def _generate_example_problems(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆç¤ºä¾‹é¢˜ç›®"""
        return [
            {
                "id": f"example_{i+1}",
                "title": f"ç¤ºä¾‹é¢˜ç›®{i+1}",
                "description": f"è¿™æ˜¯ç¤ºä¾‹é¢˜ç›®{i+1}çš„æè¿°",
                "difficulty": random.choice(["ç®€å•", "ä¸­ç­‰", "å›°éš¾"]),
                "platform": "LeetCode",
                "algorithm_tags": ["åŠ¨æ€è§„åˆ’"],
                "data_structure_tags": ["æ•°ç»„"],
                "technique_tags": ["çŠ¶æ€è½¬ç§»"],
                "solutions": [],
                "code_implementations": [],
                "key_insights": [],
                "step_by_step_explanation": [],
                "clickable": True
            }
            for i in range(3)
        ]
    
    def _generate_similar_problems(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆç›¸ä¼¼é¢˜ç›®"""
        # ç”Ÿæˆé«˜è´¨é‡çš„ç›¸ä¼¼é¢˜ç›®æ¨è
        problems = [
            {
                "title": "çˆ¬æ¥¼æ¢¯",
                "hybrid_score": 0.92,
                "embedding_score": 0.88,
                "tag_score": 0.85,
                "shared_tags": ["åŠ¨æ€è§„åˆ’", "æ•°å­¦"],
                "learning_path": "åŸºç¡€åŠ¨æ€è§„åˆ’ â†’ çŠ¶æ€è½¬ç§» â†’ ä¼˜åŒ–ç©ºé—´å¤æ‚åº¦",
                "recommendation_reason": "è¿™æ˜¯åŠ¨æ€è§„åˆ’çš„ç»å…¸å…¥é—¨é¢˜ç›®ï¼Œä¸æ‚¨çš„é—®é¢˜åœ¨çŠ¶æ€è½¬ç§»æ€æƒ³ä¸Šé«˜åº¦ç›¸ä¼¼ï¼Œæ˜¯ç†è§£åŠ¨æ€è§„åˆ’æ ¸å¿ƒæ¦‚å¿µçš„æœ€ä½³èµ·ç‚¹ã€‚",
                "learning_path_explanation": "ä»ç®€å•çš„é€’æ¨å…³ç³»å¼€å§‹ï¼Œé€æ­¥ç†è§£çŠ¶æ€å®šä¹‰å’Œè½¬ç§»æ–¹ç¨‹çš„è®¾è®¡æ€è·¯",
                "recommendation_strength": "å¼ºæ¨è",
                "complete_info": {
                    "id": "climbing_stairs",
                    "title": "çˆ¬æ¥¼æ¢¯",
                    "difficulty": "ç®€å•",
                    "platform": "LeetCode",
                    "algorithm_tags": ["åŠ¨æ€è§„åˆ’"],
                    "data_structure_tags": ["æ•°ç»„"],
                    "technique_tags": ["çŠ¶æ€è½¬ç§»"]
                },
                "clickable": True
            },
            {
                "title": "æ–æ³¢é‚£å¥‘æ•°",
                "hybrid_score": 0.89,
                "embedding_score": 0.85,
                "tag_score": 0.82,
                "shared_tags": ["åŠ¨æ€è§„åˆ’", "é€’å½’", "æ•°å­¦"],
                "learning_path": "é€’å½’æ€ç»´ â†’ è®°å¿†åŒ–æœç´¢ â†’ åŠ¨æ€è§„åˆ’",
                "recommendation_reason": "æ–æ³¢é‚£å¥‘æ•°åˆ—æ˜¯ç†è§£ä»é€’å½’åˆ°åŠ¨æ€è§„åˆ’è½¬æ¢çš„ç»å…¸ä¾‹å­ï¼Œèƒ½å¸®åŠ©æ‚¨æ·±å…¥ç†è§£åŠ¨æ€è§„åˆ’çš„æœ¬è´¨ã€‚",
                "learning_path_explanation": "é€šè¿‡å¯¹æ¯”é€’å½’å’ŒåŠ¨æ€è§„åˆ’ä¸¤ç§è§£æ³•ï¼Œç†è§£åŠ¨æ€è§„åˆ’å¦‚ä½•é¿å…é‡å¤è®¡ç®—",
                "recommendation_strength": "å¼ºæ¨è",
                "complete_info": {
                    "id": "fibonacci",
                    "title": "æ–æ³¢é‚£å¥‘æ•°",
                    "difficulty": "ç®€å•",
                    "platform": "LeetCode",
                    "algorithm_tags": ["åŠ¨æ€è§„åˆ’", "é€’å½’"],
                    "data_structure_tags": ["æ•°ç»„"],
                    "technique_tags": ["è®°å¿†åŒ–"]
                },
                "clickable": True
            },
            {
                "title": "æœ€å¤§å­æ•°ç»„å’Œ",
                "hybrid_score": 0.86,
                "embedding_score": 0.83,
                "tag_score": 0.78,
                "shared_tags": ["åŠ¨æ€è§„åˆ’", "æ•°ç»„"],
                "learning_path": "ä¸€ç»´åŠ¨æ€è§„åˆ’ â†’ çŠ¶æ€ä¼˜åŒ– â†’ Kadaneç®—æ³•",
                "recommendation_reason": "è¿™é“é¢˜å±•ç¤ºäº†åŠ¨æ€è§„åˆ’åœ¨æ•°ç»„é—®é¢˜ä¸­çš„åº”ç”¨ï¼ŒçŠ¶æ€å®šä¹‰æ›´åŠ çµæ´»ï¼Œæ˜¯è¿›é˜¶å­¦ä¹ çš„å¥½é€‰æ‹©ã€‚",
                "learning_path_explanation": "å­¦ä¹ å¦‚ä½•å®šä¹‰æ›´å¤æ‚çš„çŠ¶æ€ï¼Œä»¥åŠå¦‚ä½•ä¼˜åŒ–ç©ºé—´å¤æ‚åº¦",
                "recommendation_strength": "æ¨è",
                "complete_info": {
                    "id": "max_subarray",
                    "title": "æœ€å¤§å­æ•°ç»„å’Œ",
                    "difficulty": "ä¸­ç­‰",
                    "platform": "LeetCode",
                    "algorithm_tags": ["åŠ¨æ€è§„åˆ’"],
                    "data_structure_tags": ["æ•°ç»„"],
                    "technique_tags": ["Kadaneç®—æ³•"]
                },
                "clickable": True
            }
        ]

        # æ·»åŠ Neo4jèŠ‚ç‚¹å¯¹è±¡åˆ°æ¦‚å¿µè§£é‡Šä¸­ï¼Œç”¨äºæµ‹è¯•å‰ç«¯å¤„ç†
        if len(problems) > 0:
            # æ¨¡æ‹ŸNeo4jèŠ‚ç‚¹å¯¹è±¡
            neo4j_node_example = "<Node element_id='79' labels=frozenset({'Algorithm'}) properties={'name': 'Dynamic Programming', 'description': 'åŠ¨æ€è§„åˆ’æ˜¯ä¸€ç§ç®—æ³•è®¾è®¡æŠ€æœ¯', 'difficulty': 'medium', 'applications': ['æœ€ä¼˜åŒ–é—®é¢˜', 'è®¡æ•°é—®é¢˜'], 'time_complexity': 'O(n)', 'space_complexity': 'O(n)'}>"

            # å°†Neo4jèŠ‚ç‚¹æ·»åŠ åˆ°ç¬¬ä¸€ä¸ªé—®é¢˜çš„æ¨èç†ç”±ä¸­
            problems[0]["recommendation_reason"] += f"\n\nç›¸å…³ç®—æ³•èŠ‚ç‚¹ï¼š{neo4j_node_example}"

        return problems
    
    def _generate_integrated_response(self, query: str) -> str:
        """ç”Ÿæˆæ•´åˆå›ç­”"""
        return f"""
åŸºäºæ‚¨çš„é—®é¢˜"{query}"ï¼Œæˆ‘ä¸ºæ‚¨æä¾›ä»¥ä¸‹è§£ç­”ï¼š

è¿™æ˜¯ä¸€ä¸ªå…³äºç®—æ³•å’Œæ•°æ®ç»“æ„çš„é—®é¢˜ã€‚åœ¨å®é™…çš„ç³»ç»Ÿä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨å¤šä¸ªæ™ºèƒ½ä½“åä½œç”Ÿæˆè¯¦ç»†çš„å›ç­”ï¼ŒåŒ…æ‹¬ï¼š

1. **æ¦‚å¿µè§£é‡Š**: è¯¦ç»†è§£é‡Šç›¸å…³æ¦‚å¿µçš„å®šä¹‰ã€åŸç†å’Œåº”ç”¨åœºæ™¯
2. **ç¤ºä¾‹é¢˜ç›®**: æä¾›ç›¸å…³çš„ç»ƒä¹ é¢˜ç›®å¸®åŠ©ç†è§£
3. **ç›¸ä¼¼æ¨è**: æ¨èç›¸ä¼¼çš„é¢˜ç›®å’Œå­¦ä¹ è·¯å¾„
4. **ä»£ç å®ç°**: æä¾›å…·ä½“çš„ä»£ç ç¤ºä¾‹å’Œå®ç°è¦ç‚¹

ç›®å‰æ‚¨çœ‹åˆ°çš„æ˜¯æ¨¡æ‹Ÿå“åº”ã€‚è¦è·å¾—å®Œæ•´åŠŸèƒ½ï¼Œè¯·ç¡®ä¿ï¼š
- åŸå§‹é—®ç­”ç³»ç»Ÿæ¨¡å—å¯ç”¨
- æ¨¡å‹æ–‡ä»¶å’Œæ•°æ®æ–‡ä»¶å·²æ­£ç¡®æ”¾ç½®
- Neo4jæ•°æ®åº“åŒ…å«çŸ¥è¯†å›¾è°±æ•°æ®

æ‚¨å¯ä»¥ç»§ç»­æµ‹è¯•ç•Œé¢åŠŸèƒ½ï¼Œæ‰€æœ‰äº¤äº’éƒ½ä¼šæ­£å¸¸å·¥ä½œã€‚
        """.strip()
    
    def _generate_graph_data(self, entities: List[str]) -> Dict[str, Any]:
        """ç”Ÿæˆå›¾è°±æ•°æ®"""
        nodes = []
        edges = []

        # æ·»åŠ ä¸­å¿ƒèŠ‚ç‚¹
        if entities:
            center_entity = entities[0]
            center_id = f"concept_{center_entity.replace(' ', '_')}"
            nodes.append({
                "id": center_id,
                "label": center_entity,
                "type": "Concept",
                "properties": {"is_center": True},
                "clickable": True
            })

            # æ·»åŠ ç›¸å…³æ¦‚å¿µèŠ‚ç‚¹
            related_concepts = ["åŸºç¡€æ¦‚å¿µ", "é«˜çº§åº”ç”¨", "ç›¸å…³ç®—æ³•", "å®é™…åº”ç”¨"]
            for i, concept in enumerate(related_concepts):
                node_id = f"related_{i}"
                nodes.append({
                    "id": node_id,
                    "label": concept,
                    "type": "Concept",
                    "properties": {},
                    "clickable": True
                })

                edges.append({
                    "source": center_id,
                    "target": node_id,
                    "relationship": "RELATED_TO",
                    "properties": {}
                })

            # æ·»åŠ ç¤ºä¾‹é¢˜ç›®èŠ‚ç‚¹
            for i in range(3):
                problem_id = f"problem_{i+1}"
                nodes.append({
                    "id": problem_id,
                    "label": f"ç¤ºä¾‹é¢˜ç›®{i+1}",
                    "type": "Problem",
                    "properties": {"difficulty": "ä¸­ç­‰"},
                    "clickable": True
                })

                edges.append({
                    "source": center_id,
                    "target": problem_id,
                    "relationship": "EXAMPLE_OF",
                    "properties": {}
                })

            # æ·»åŠ ç®—æ³•èŠ‚ç‚¹
            algorithm_id = f"algorithm_{center_entity.replace(' ', '_')}"
            nodes.append({
                "id": algorithm_id,
                "label": f"{center_entity}ç®—æ³•",
                "type": "Algorithm",
                "properties": {},
                "clickable": True
            })

            edges.append({
                "source": center_id,
                "target": algorithm_id,
                "relationship": "IMPLEMENTS",
                "properties": {}
            })

        return {
            "nodes": nodes,
            "edges": edges,
            "center_node": center_id if entities else None,
            "layout_type": "force"
        }
    
    def _generate_reasoning_path(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ¨ç†è·¯å¾„"""
        return [
            {
                "agent_name": "analyzer",
                "step_type": "analysis",
                "description": "åˆ†ææŸ¥è¯¢æ„å›¾å’Œå…³é”®å®ä½“",
                "status": "success",
                "start_time": datetime.now().isoformat(),
                "end_time": datetime.now().isoformat(),
                "confidence": 0.9,
                "result": {"entities": ["åŠ¨æ€è§„åˆ’"]}
            },
            {
                "agent_name": "knowledge_retriever",
                "step_type": "retrieval",
                "description": "ä»çŸ¥è¯†å›¾è°±æ£€ç´¢ç›¸å…³ä¿¡æ¯",
                "status": "success",
                "start_time": datetime.now().isoformat(),
                "end_time": datetime.now().isoformat(),
                "confidence": 0.85,
                "result": {"count": 15, "sources": ["çŸ¥è¯†å›¾è°±", "é¢˜ç›®åº“"]}
            },
            {
                "agent_name": "concept_explainer",
                "step_type": "explanation",
                "description": "ç”Ÿæˆæ¦‚å¿µè§£é‡Šå’Œç¤ºä¾‹",
                "status": "success",
                "start_time": datetime.now().isoformat(),
                "end_time": datetime.now().isoformat(),
                "confidence": 0.88,
                "result": {"concepts": ["åŠ¨æ€è§„åˆ’", "çŠ¶æ€è½¬ç§»"]}
            },
            {
                "agent_name": "integrator",
                "step_type": "integration",
                "description": "æ•´åˆæ‰€æœ‰ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆå›ç­”",
                "status": "success",
                "start_time": datetime.now().isoformat(),
                "end_time": datetime.now().isoformat(),
                "confidence": 0.92,
                "result": {"sections": ["æ¦‚å¿µè§£é‡Š", "ç¤ºä¾‹é¢˜ç›®", "ç›¸ä¼¼æ¨è"]}
            }
        ]
    
    async def find_similar_problems(self, problem_title: str, count: int = 5):
        """æ¨¡æ‹ŸæŸ¥æ‰¾ç›¸ä¼¼é¢˜ç›®"""
        # æ¨¡æ‹Ÿå¼‚æ­¥å¤„ç†
        await asyncio.sleep(0.3)
        
        class MockResponse:
            def __init__(self, content):
                self.content = content
        
        similar_data = self.rec_system.find_similar_problems(problem_title, count)
        return MockResponse(similar_data)
