import asyncio
import uuid
import time
from typing import Dict, Any, List, Optional, AsyncGenerator
from datetime import datetime
import json
import logging

from app.models import (
    QARequest, QAResponse, StreamingResponse,
    ConceptExplanation, ProblemInfo, SimilarProblem,
    AgentStep, ResponseStatus, GraphData, GraphNode, GraphEdge
)
from app.core.config import settings
from app.services.tag_service import tag_service
from qa.multi_agent_qa import GraphEnhancedMultiAgentSystem

logger = logging.getLogger(__name__)

class QAService:
    """é—®ç­”æœåŠ¡"""
    
    def __init__(self, qa_system: GraphEnhancedMultiAgentSystem):
        self.qa_system = qa_system
        self.active_sessions = {}  # å­˜å‚¨æ´»è·ƒä¼šè¯
        
    async def process_query(self, request: QARequest) -> QAResponse:
        """å¤„ç†é—®ç­”æŸ¥è¯¢"""
        start_time = time.time()
        response_id = str(uuid.uuid4())
        
        try:
            # è°ƒç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå¤„ç†æŸ¥è¯¢
            result = await self.qa_system.process_query(request.query)
            
            # è½¬æ¢ä¸ºAPIå“åº”æ ¼å¼
            response = await self._convert_to_api_response(
                result, request, response_id, start_time
            )
            
            # å­˜å‚¨ä¼šè¯ä¿¡æ¯
            if request.session_id:
                self._update_session(request.session_id, request, response)
            
            return response
            
        except Exception as e:
            logger.error(f"å¤„ç†æŸ¥è¯¢å¤±è´¥: {e}")
            processing_time = time.time() - start_time
            
            return QAResponse(
                response_id=response_id,
                query=request.query,
                intent="error",
                entities=[],
                integrated_response=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æŸ¥è¯¢æ—¶é‡åˆ°äº†é—®é¢˜: {str(e)}",
                status=ResponseStatus.ERROR,
                processing_time=processing_time,
                metadata={"error": str(e)}
            )
    
    async def process_query_streaming(
        self, request: QARequest
    ) -> AsyncGenerator[StreamingResponse, None]:
        """æµå¼å¤„ç†é—®ç­”æŸ¥è¯¢"""
        response_id = str(uuid.uuid4())
        
        try:
            # å‘é€å¼€å§‹æ¶ˆæ¯
            yield StreamingResponse(
                type="start",
                data={"response_id": response_id, "query": request.query},
                step_id="start"
            )
            
            # å®æ—¶æµå¼å¤„ç† - å…ˆå‘é€æ¨¡æ‹Ÿæ­¥éª¤ï¼Œç„¶åå¤„ç†æŸ¥è¯¢
            # æ­¥éª¤1: åˆ†ææŸ¥è¯¢æ„å›¾
            yield StreamingResponse(
                type="step",
                data={
                    "step_number": 1,
                    "total_steps": 4,
                    "agent_name": "analyzer",
                    "description": "åˆ†ææŸ¥è¯¢æ„å›¾å’Œå…³é”®å®ä½“",
                    "status": "processing",
                    "start_time": datetime.now().isoformat(),
                    "step_type": "analysis"
                },
                step_id="step_1"
            )

            await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´

            yield StreamingResponse(
                type="step_complete",
                data={
                    "step_number": 1,
                    "agent_name": "analyzer",
                    "status": "success",
                    "end_time": datetime.now().isoformat(),
                    "confidence": 0.9,
                    "result": {"intent": "æ¦‚å¿µè§£é‡Š", "entities": ["åŠ¨æ€è§„åˆ’"]}
                },
                step_id="step_1_complete"
            )

            # æ­¥éª¤2: çŸ¥è¯†æ£€ç´¢
            yield StreamingResponse(
                type="step",
                data={
                    "step_number": 2,
                    "total_steps": 4,
                    "agent_name": "knowledge_retriever",
                    "description": "ä»çŸ¥è¯†å›¾è°±æ£€ç´¢ç›¸å…³ä¿¡æ¯",
                    "status": "processing",
                    "start_time": datetime.now().isoformat(),
                    "step_type": "retrieval"
                },
                step_id="step_2"
            )

            await asyncio.sleep(1.0)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´

            yield StreamingResponse(
                type="step_complete",
                data={
                    "step_number": 2,
                    "agent_name": "knowledge_retriever",
                    "status": "success",
                    "end_time": datetime.now().isoformat(),
                    "confidence": 0.85,
                    "result": {"concept_found": True, "examples_count": 3}
                },
                step_id="step_2_complete"
            )

            # æ­¥éª¤3: æ¦‚å¿µè§£é‡Šç”Ÿæˆ
            yield StreamingResponse(
                type="step",
                data={
                    "step_number": 3,
                    "total_steps": 4,
                    "agent_name": "concept_explainer",
                    "description": "ç”Ÿæˆæ¦‚å¿µè§£é‡Šå’Œç¤ºä¾‹",
                    "status": "processing",
                    "start_time": datetime.now().isoformat(),
                    "step_type": "explanation"
                },
                step_id="step_3"
            )

            await asyncio.sleep(1.5)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´

            yield StreamingResponse(
                type="step_complete",
                data={
                    "step_number": 3,
                    "agent_name": "concept_explainer",
                    "status": "success",
                    "end_time": datetime.now().isoformat(),
                    "confidence": 0.88,
                    "result": {"explanation_generated": True}
                },
                step_id="step_3_complete"
            )

            # æ­¥éª¤4: æ•´åˆå›ç­”
            yield StreamingResponse(
                type="step",
                data={
                    "step_number": 4,
                    "total_steps": 4,
                    "agent_name": "integrator",
                    "description": "æ•´åˆæ‰€æœ‰ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆå›ç­”",
                    "status": "processing",
                    "start_time": datetime.now().isoformat(),
                    "step_type": "integration"
                },
                step_id="step_4"
            )

            # åœ¨æœ€åä¸€æ­¥å®é™…å¤„ç†æŸ¥è¯¢
            result = await self.qa_system.process_query(request.query)
            reasoning_path = result.get("reasoning_path", [])

            yield StreamingResponse(
                type="step_complete",
                data={
                    "step_number": 4,
                    "agent_name": "integrator",
                    "status": "success",
                    "end_time": datetime.now().isoformat(),
                    "confidence": 0.9,
                    "result": {
                        "response_generated": True,
                        "response_length": len(result.get("integrated_response", ""))
                    }
                },
                step_id="step_4_complete"
            )

            print(f"QAService - è·å–åˆ°æ¨ç†è·¯å¾„: {len(reasoning_path)} ä¸ªæ­¥éª¤")
            for i, step in enumerate(reasoning_path):
                print(f"æ­¥éª¤ {i+1}: {step.get('agent_name')} - {step.get('description')}")

            # è·³è¿‡åŸæœ‰çš„æ¨ç†æ­¥éª¤å‘é€ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»å®æ—¶å‘é€äº†
            # ç›´æ¥å‘é€æœ€ç»ˆç»“æœ
            
            # å‘é€æœ€ç»ˆç»“æœ
            final_response = await self._convert_to_api_response(
                result, request, response_id, time.time()
            )
            
            yield StreamingResponse(
                type="final_result",
                data=final_response.dict(),
                is_final=True
            )
            
        except Exception as e:
            logger.error(f"æµå¼å¤„ç†å¤±è´¥: {e}")
            yield StreamingResponse(
                type="error",
                data={"error": str(e)},
                is_final=True
            )
    
    async def get_similar_problems(
        self, problem_title: str, count: int = 5
    ) -> List[SimilarProblem]:
        """è·å–ç›¸ä¼¼é¢˜ç›®"""
        try:
            # ä½¿ç”¨ç›¸ä¼¼é¢˜ç›®æŸ¥æ‰¾Agent
            similar_finder = self.qa_system.similar_problem_finder
            response = await similar_finder.find_similar_problems(problem_title, count)
            
            if response and response.content:
                result_list = []
                for item in response.content:
                    # æ¸…ç†shared_conceptsä¸­çš„Neo4jèŠ‚ç‚¹
                    raw_shared_concepts = item.get("similarity_analysis", {}).get("shared_concepts", [])
                    processed_concepts = tag_service.clean_and_standardize_tags(raw_shared_concepts)
                    formatted_concepts = tag_service.format_tags_for_display(processed_concepts)
                    clean_shared_tags = [tag['name'] for tag in formatted_concepts]

                    result_list.append(SimilarProblem(
                        title=item.get("title", ""),
                        hybrid_score=item.get("hybrid_score", 0.0),
                        embedding_score=item.get("similarity_analysis", {}).get("embedding_similarity", 0.0),
                        tag_score=item.get("similarity_analysis", {}).get("tag_similarity", 0.0),
                        shared_tags=clean_shared_tags,  # ä½¿ç”¨æ¸…ç†åçš„æ ‡ç­¾
                        learning_path=item.get("learning_path", {}).get("path_description", ""),
                        recommendation_reason=item.get("recommendation_reason", ""),
                        learning_path_explanation=item.get("learning_path", {}).get("reasoning", ""),
                        recommendation_strength=item.get("recommendation_strength", ""),
                        complete_info=self._convert_to_problem_info(item.get("complete_info", {}))
                    ))
                return result_list
            return []
            
        except Exception as e:
            logger.error(f"è·å–ç›¸ä¼¼é¢˜ç›®å¤±è´¥: {e}")
            return []
    
    async def handle_concept_click(
        self, concept_name: str, source_query: str, context_type: str
    ) -> QAResponse:
        """å¤„ç†æ¦‚å¿µç‚¹å‡»äº‹ä»¶"""
        # æ„é€ æ–°çš„æŸ¥è¯¢è¯·æ±‚
        new_query = f"è¯·è¯¦ç»†è§£é‡Š{concept_name}çš„æ¦‚å¿µ"
        
        request = QARequest(
            query=new_query,
            context={
                "source_query": source_query,
                "context_type": context_type,
                "triggered_by": "concept_click"
            }
        )
        
        return await self.process_query(request)
    
    def _update_session(self, session_id: str, request: QARequest, response: QAResponse):
        """æ›´æ–°ä¼šè¯ä¿¡æ¯"""
        if session_id not in self.active_sessions:
            self.active_sessions[session_id] = {
                "created_at": datetime.now(),
                "queries": []
            }
        
        self.active_sessions[session_id]["queries"].append({
            "request": request.dict(),
            "response": response.dict(),
            "timestamp": datetime.now()
        })
        
        # é™åˆ¶ä¼šè¯å†å²é•¿åº¦
        if len(self.active_sessions[session_id]["queries"]) > 50:
            self.active_sessions[session_id]["queries"] = \
                self.active_sessions[session_id]["queries"][-50:]
    
    async def _convert_to_api_response(
        self, result: Dict[str, Any], request: QARequest, 
        response_id: str, start_time: float
    ) -> QAResponse:
        """å°†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç»“æœè½¬æ¢ä¸ºAPIå“åº”æ ¼å¼"""
        
        processing_time = time.time() - start_time
        
        # è½¬æ¢æ¦‚å¿µè§£é‡Š
        concept_explanation = None
        if result.get("concept_explanation"):
            concept_data = result["concept_explanation"]

            # æ·±åº¦æ¸…ç†æ‰€æœ‰æ•°æ®ï¼Œç¡®ä¿æ²¡æœ‰å¯¹è±¡å¼•ç”¨
            concept_data = self._deep_clean_objects(concept_data)

            # æ¸…ç†learning_progressionæ•°æ®
            learning_progression = concept_data.get("learning_progression", {})
            if isinstance(learning_progression, dict):
                # ç¡®ä¿prerequisiteså’Œnext_conceptsæ˜¯åˆ—è¡¨
                for key in ["prerequisites", "next_concepts"]:
                    if key in learning_progression:
                        value = learning_progression[key]
                        if isinstance(value, str):
                            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ŒæŒ‰é€—å·åˆ†å‰²è½¬æ¢ä¸ºåˆ—è¡¨
                            learning_progression[key] = [item.strip() for item in value.split(",") if item.strip()]
                        elif not isinstance(value, list):
                            learning_progression[key] = []

            concept_explanation = ConceptExplanation(
                concept_name=concept_data.get("concept_name", ""),
                definition=concept_data.get("definition", ""),
                core_principles=concept_data.get("core_principles", []),
                when_to_use=concept_data.get("when_to_use"),
                advantages=concept_data.get("advantages", []),
                disadvantages=concept_data.get("disadvantages", []),
                implementation_key_points=concept_data.get("implementation_key_points", []),
                common_variations=concept_data.get("common_variations", []),
                real_world_applications=concept_data.get("real_world_applications", []),
                learning_progression=learning_progression,
                visual_explanation=concept_data.get("visual_explanation"),
                clickable_concepts=self._extract_clickable_concepts(concept_data)
            )
        
        # è½¬æ¢ç¤ºä¾‹é¢˜ç›®
        example_problems = [
            self._convert_to_problem_info(self._deep_clean_objects(problem))
            for problem in result.get("example_problems", [])
        ]
        
        # è½¬æ¢ç›¸ä¼¼é¢˜ç›®
        similar_problems_data = result.get("similar_problems", [])
        similar_problems = []

        for item in similar_problems_data:
            try:
                # æ·±åº¦æ¸…ç†æ•°æ®
                cleaned_item = self._deep_clean_objects(item)

                # éªŒè¯å¿…è¦å­—æ®µ
                title = str(cleaned_item.get("title", ""))
                if not title or title == "æ— " or title.strip() == "":
                    continue

                # è·å–æ¨èåˆ†æ•°
                hybrid_score = float(cleaned_item.get("hybrid_score", 0.0))

                # è¿‡æ»¤ä½è´¨é‡æ¨èï¼šåˆ†æ•°è¿‡ä½çš„æ¨èä¸æ˜¾ç¤º
                if hybrid_score < 0.5:  # è®¾ç½®æœ€ä½æ¨èåˆ†æ•°é˜ˆå€¼
                    logger.info(f"è¿‡æ»¤ä½è´¨é‡æ¨è: {title} (åˆ†æ•°: {hybrid_score})")
                    continue

                # æ£€æŸ¥æ¨èç†ç”±çš„åˆç†æ€§
                recommendation_reason = str(cleaned_item.get("recommendation_reason", ""))
                if not recommendation_reason or len(recommendation_reason.strip()) < 10:
                    logger.info(f"è¿‡æ»¤æ— æ•ˆæ¨èç†ç”±: {title}")
                    continue

                # å¤„ç†å’Œæ¸…ç†æ ‡ç­¾
                raw_shared_tags = cleaned_item.get("similarity_analysis", {}).get("shared_concepts", [])
                processed_tags = tag_service.clean_and_standardize_tags(raw_shared_tags)
                formatted_tags = tag_service.format_tags_for_display(processed_tags)

                similar_problem = SimilarProblem(
                    title=title,
                    hybrid_score=hybrid_score,
                    embedding_score=float(cleaned_item.get("similarity_analysis", {}).get("embedding_similarity", 0.0)),
                    tag_score=float(cleaned_item.get("similarity_analysis", {}).get("tag_similarity", 0.0)),
                    shared_tags=[tag['display_name'] for tag in formatted_tags],  # ä½¿ç”¨æ ¼å¼åŒ–åçš„æ˜¾ç¤ºåç§°
                    learning_path=str(cleaned_item.get("learning_path", {}).get("path_description", "")),
                    recommendation_reason=recommendation_reason,
                    learning_path_explanation=str(cleaned_item.get("learning_path", {}).get("reasoning", "")),
                    recommendation_strength=str(cleaned_item.get("recommendation_strength", "")),
                    complete_info=self._convert_to_problem_info(self._deep_clean_objects(cleaned_item.get("complete_info", {})))
                )
                similar_problems.append(similar_problem)
            except Exception as e:
                logger.warning(f"å¤„ç†ç›¸ä¼¼é¢˜ç›®æ•°æ®å¤±è´¥: {e}")
                continue

        # ä¼˜å…ˆä½¿ç”¨å›¾æ£€ç´¢æ¨èï¼Œç„¶åæ˜¯embeddingæ¨èï¼Œæœ€åæ˜¯LLMå¤‡ç”¨æ¨è
        if not similar_problems:
            # 1. é¦–å…ˆå°è¯•Neo4jå›¾æ£€ç´¢æ¨è - æŸ¥è¯¢æ‰€æœ‰è¯†åˆ«å‡ºçš„å®ä½“
            try:
                from app.core.deps import get_neo4j_api
                neo4j_api = get_neo4j_api()

                entities = result.get("entities", [])
                logger.info(f"å°è¯•å›¾æ£€ç´¢æ¨èï¼Œæ‰€æœ‰å®ä½“: {entities}")

                # å¯¹æ¯ä¸ªå®ä½“éƒ½å°è¯•æŸ¥è¯¢
                for entity in entities:
                    try:
                        logger.info(f"æŸ¥è¯¢å®ä½“: {entity}")

                        # 1.1 ç›´æ¥æŸ¥è¯¢èŠ‚ç‚¹ä¿¡æ¯
                        node_info = neo4j_api.get_node_by_name(entity)
                        if node_info:
                            logger.info(f"æ‰¾åˆ°èŠ‚ç‚¹: {entity} - {node_info.get('type', 'Unknown')}")

                            # å¦‚æœæ˜¯é¢˜ç›®èŠ‚ç‚¹ï¼Œè·å–å…¶è¯¦ç»†ä¿¡æ¯
                            if node_info.get('type') == 'Problem':
                                problem_detail = neo4j_api.get_problem_by_title(entity)
                                if problem_detail:
                                    # æ¸…ç†problem_detailä¸­å¯èƒ½çš„Neo4jèŠ‚ç‚¹å¯¹è±¡
                                    cleaned_problem_detail = self._deep_clean_objects(problem_detail)

                                    # æ·»åŠ é¢˜ç›®æœ¬èº«ä½œä¸º"ç›¸å…³é¢˜ç›®"
                                    direct_problem = SimilarProblem(
                                        title=entity,
                                        hybrid_score=1.0,  # ç›´æ¥åŒ¹é…ï¼Œæœ€é«˜åˆ†
                                        embedding_score=0.0,
                                        tag_score=1.0,
                                        shared_tags=["ç›´æ¥åŒ¹é…"],
                                        learning_path=f"ç›´æ¥åŒ¹é…çš„é¢˜ç›®ï¼šã€Š{entity}ã€‹",
                                        recommendation_reason=f"ç”¨æˆ·æŸ¥è¯¢ç›´æ¥åŒ¹é…åˆ°é¢˜ç›®ã€Š{entity}ã€‹",
                                        learning_path_explanation="è¿™æ˜¯ç”¨æˆ·æŸ¥è¯¢ä¸­ç›´æ¥æåˆ°çš„é¢˜ç›®",
                                        recommendation_strength="ç›´æ¥åŒ¹é…",
                                        complete_info=self._convert_to_problem_info(cleaned_problem_detail)
                                    )
                                    similar_problems.append(direct_problem)

                        # 1.2 è·å–ç›¸ä¼¼é¢˜ç›®
                        graph_similar = neo4j_api.get_similar_problems(entity, limit=3)
                        if graph_similar:
                            logger.info(f"å®ä½“ {entity} æ‰¾åˆ° {len(graph_similar)} ä¸ªç›¸ä¼¼é¢˜ç›®")
                            for similar in graph_similar:
                                # é¿å…é‡å¤æ·»åŠ 
                                if not any(p.title == similar.get("title", "") for p in similar_problems):
                                    # å¤„ç†å›¾æ£€ç´¢çš„æ ‡ç­¾
                                    graph_tags = ["ğŸ”— å›¾å…³ç³»ç›¸ä¼¼", f"ğŸ“Š å…³è”å®ä½“: {entity}"]
                                    processed_graph_tags = tag_service.clean_and_standardize_tags(graph_tags)
                                    formatted_graph_tags = tag_service.format_tags_for_display(processed_graph_tags)

                                    # æ¸…ç†similarå¯¹è±¡ä¸­å¯èƒ½çš„Neo4jèŠ‚ç‚¹
                                    cleaned_similar = self._deep_clean_objects(similar)

                                    graph_problem = SimilarProblem(
                                        title=similar.get("title", ""),
                                        hybrid_score=float(similar.get("similarity_score", 0.8)),
                                        embedding_score=0.0,  # å›¾æ£€ç´¢ä¸ä½¿ç”¨embedding
                                        tag_score=float(similar.get("similarity_score", 0.8)),
                                        shared_tags=[tag['display_name'] for tag in formatted_graph_tags],
                                        learning_path=f"åŸºäºçŸ¥è¯†å›¾è°±çš„ç›¸ä¼¼é¢˜ç›®æ¨èï¼ˆå…³è”å®ä½“ï¼š{entity}ï¼‰",
                                        recommendation_reason=f"åœ¨çŸ¥è¯†å›¾è°±ä¸­ä¸ã€Š{entity}ã€‹æœ‰ç›¸ä¼¼å…³ç³»",
                                        learning_path_explanation="é€šè¿‡ç®—æ³•ã€æ•°æ®ç»“æ„æˆ–æŠ€å·§çš„å…±åŒå…³ç³»å‘ç°çš„ç›¸ä¼¼é¢˜ç›®",
                                        recommendation_strength="å›¾æ¨è",
                                        complete_info=self._convert_to_problem_info(cleaned_similar)
                                    )
                                    similar_problems.append(graph_problem)
                        else:
                            logger.info(f"å®ä½“ {entity} æœªæ‰¾åˆ°ç›¸ä¼¼é¢˜ç›®")

                    except Exception as entity_error:
                        logger.error(f"æŸ¥è¯¢å®ä½“ {entity} å¤±è´¥: {entity_error}")
                        continue

                if similar_problems:
                    logger.info(f"å›¾æ£€ç´¢æ€»å…±æ‰¾åˆ° {len(similar_problems)} ä¸ªç›¸å…³é¢˜ç›®")
                else:
                    logger.info("æ‰€æœ‰å®ä½“çš„å›¾æ£€ç´¢éƒ½æœªæ‰¾åˆ°ç›¸ä¼¼é¢˜ç›®")

            except Exception as e:
                logger.error(f"å›¾æ£€ç´¢æ¨èå¤±è´¥: {e}")

        # 2. å¦‚æœå›¾æ£€ç´¢ç»“æœä¸è¶³ï¼Œå°è¯•å¢å¼ºæ¨èç³»ç»Ÿ
        if len(similar_problems) < 3:
            try:
                from app.core.deps import get_enhanced_recommendation_system
                enhanced_rec_system = get_enhanced_recommendation_system()

                # æ£€æŸ¥å¢å¼ºæ¨èç³»ç»Ÿæ˜¯å¦å¯ç”¨
                if enhanced_rec_system is not None:
                    logger.info(f"ä½¿ç”¨å¢å¼ºæ¨èç³»ç»Ÿè¡¥å……æ¨è")

                    # å°è¯•ä½¿ç”¨æŸ¥è¯¢ä¸­çš„å®ä½“ä½œä¸ºé¢˜ç›®åç§°
                    entities = result.get("entities", [])
                    main_entity = entities[0] if entities else None
                    query_title = main_entity if main_entity else request.query

                    # ç¡®ä¿top_kè‡³å°‘ä¸º1
                    remaining_slots = max(1, 5 - len(similar_problems))

                    rec_result = enhanced_rec_system.recommend(
                        query_title=query_title,
                        top_k=remaining_slots,
                        alpha=0.7,
                        enable_diversity=True,
                        diversity_lambda=0.3
                    )

                    logger.info(f"å¢å¼ºæ¨èç³»ç»Ÿè¿”å›ç»“æœ: {rec_result.get('status', 'unknown')}")

                    if "error" not in rec_result and "recommendations" in rec_result:
                        for rec in rec_result["recommendations"]:
                            try:
                                # å¤„ç†å¢å¼ºæ¨èç³»ç»Ÿçš„æ ‡ç­¾
                                raw_enhanced_tags = rec.get("shared_tags", [])
                                processed_enhanced_tags = tag_service.clean_and_standardize_tags(raw_enhanced_tags)
                                formatted_enhanced_tags = tag_service.format_tags_for_display(processed_enhanced_tags)

                                # å®‰å…¨åœ°è·å–learning_pathä¿¡æ¯
                                learning_path_info = rec.get("learning_path", {})
                                if isinstance(learning_path_info, dict):
                                    learning_path_desc = learning_path_info.get("path_description",
                                                                              learning_path_info.get("difficulty_progression", "æ¨èå­¦ä¹ "))
                                    learning_path_reasoning = learning_path_info.get("reasoning",
                                                                                    learning_path_info.get("estimated_time", "ç›¸å…³ç®—æ³•ç»ƒä¹ "))
                                else:
                                    learning_path_desc = str(learning_path_info) if learning_path_info else "æ¨èå­¦ä¹ "
                                    learning_path_reasoning = "ç›¸å…³ç®—æ³•ç»ƒä¹ "

                                enhanced_problem = SimilarProblem(
                                    title=rec["title"],
                                    hybrid_score=float(rec.get("hybrid_score", 0.8)),
                                    embedding_score=float(rec.get("embedding_score", 0.7)),
                                    tag_score=float(rec.get("tag_score", 0.6)),
                                    shared_tags=[tag['display_name'] for tag in formatted_enhanced_tags],
                                    learning_path=learning_path_desc,
                                    recommendation_reason=rec.get("recommendation_reason", "ç®—æ³•ç›¸ä¼¼æ€§æ¨è"),
                                    learning_path_explanation=learning_path_reasoning,
                                    recommendation_strength="å¢å¼ºæ¨è",
                                    complete_info=None
                                )
                                similar_problems.append(enhanced_problem)
                            except Exception as rec_error:
                                logger.warning(f"å¤„ç†å¢å¼ºæ¨èç»“æœæ—¶å‡ºé”™: {rec_error}, æ¨èæ•°æ®: {rec}")
                                continue
                        logger.info(f"å¢å¼ºæ¨èç³»ç»Ÿè¡¥å……äº† {len(rec_result['recommendations'])} ä¸ªæ¨è")
                    else:
                        error_msg = rec_result.get('error', 'æœªçŸ¥é”™è¯¯')
                        logger.warning(f"å¢å¼ºæ¨èç³»ç»Ÿè¿”å›é”™è¯¯: {error_msg}")

                        # å¦‚æœæ˜¯é¢˜ç›®æœªæ‰¾åˆ°é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨å»ºè®®çš„é¢˜ç›®
                        if "suggestions" in rec_result and rec_result["suggestions"]:
                            suggested_title = rec_result["suggestions"][0]
                            logger.info(f"å°è¯•ä½¿ç”¨å»ºè®®é¢˜ç›®: {suggested_title}")

                            rec_result_retry = enhanced_rec_system.recommend(
                                query_title=suggested_title,
                                top_k=3,
                                alpha=0.7,
                                enable_diversity=True,
                                diversity_lambda=0.3
                            )

                            if "error" not in rec_result_retry and "recommendations" in rec_result_retry:
                                for rec in rec_result_retry["recommendations"]:
                                    # å¤„ç†å¢å¼ºæ¨èçš„æ ‡ç­¾
                                    raw_enhanced_tags = rec.get("shared_tags", [])
                                    processed_enhanced_tags = tag_service.clean_and_standardize_tags(raw_enhanced_tags)
                                    formatted_enhanced_tags = tag_service.format_tags_for_display(processed_enhanced_tags)

                                    enhanced_problem = SimilarProblem(
                                        title=rec["title"],
                                        hybrid_score=float(rec["hybrid_score"]) * 0.8,  # é™ä½æƒé‡å› ä¸ºæ˜¯é—´æ¥åŒ¹é…
                                        embedding_score=float(rec["embedding_score"]),
                                        tag_score=float(rec["tag_score"]),
                                        shared_tags=[tag['display_name'] for tag in formatted_enhanced_tags],
                                        learning_path=f"åŸºäºç›¸ä¼¼é¢˜ç›®ã€Š{suggested_title}ã€‹çš„æ¨è",
                                        recommendation_reason=f"é€šè¿‡ç›¸ä¼¼é¢˜ç›®ã€Š{suggested_title}ã€‹å‘ç°çš„ç›¸å…³é¢˜ç›®",
                                        learning_path_explanation=rec["learning_path"]["reasoning"],
                                        recommendation_strength="é—´æ¥å¢å¼ºæ¨è",
                                        complete_info=None
                                    )
                                    similar_problems.append(enhanced_problem)
                                logger.info(f"é—´æ¥å¢å¼ºæ¨èè¡¥å……äº† {len(rec_result_retry['recommendations'])} ä¸ªæ¨è")
                else:
                    logger.warning("å¢å¼ºæ¨èç³»ç»Ÿä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨åŸå§‹æ¨èç³»ç»Ÿ")
                    # å›é€€åˆ°åŸå§‹æ¨èç³»ç»Ÿ
                    from app.core.deps import get_recommendation_system
                    rec_system = get_recommendation_system()

                    if rec_system and hasattr(rec_system, 'recommend'):
                        logger.info(f"ä½¿ç”¨åŸå§‹æ¨èç³»ç»Ÿè¡¥å……æ¨è")
                        entities = result.get("entities", [])
                        main_entity = entities[0] if entities else None
                        query_title = main_entity if main_entity else request.query

                        # ç¡®ä¿top_kè‡³å°‘ä¸º1
                        remaining_slots = max(1, 5 - len(similar_problems))

                        rec_result = rec_system.recommend(
                            query_title=query_title,
                            top_k=remaining_slots,
                            alpha=0.7,
                            enable_diversity=True,
                            diversity_lambda=0.3
                        )

                        logger.info(f"æ¨èç³»ç»Ÿè¿”å›ç»“æœ: {rec_result.get('status', 'unknown')}")

                        if "error" not in rec_result and "recommendations" in rec_result:
                            for rec in rec_result["recommendations"]:
                                try:
                                    raw_tags = rec.get("shared_tags", [])
                                    processed_tags = tag_service.clean_and_standardize_tags(raw_tags)
                                    formatted_tags = tag_service.format_tags_for_display(processed_tags)

                                    # å®‰å…¨åœ°è·å–learning_pathä¿¡æ¯
                                    learning_path_info = rec.get("learning_path", {})
                                    if isinstance(learning_path_info, dict):
                                        learning_path_desc = learning_path_info.get("path_description",
                                                                                  learning_path_info.get("difficulty_progression", "æ¨èå­¦ä¹ "))
                                        learning_path_reasoning = learning_path_info.get("reasoning",
                                                                                        learning_path_info.get("estimated_time", "ç›¸å…³ç®—æ³•ç»ƒä¹ "))
                                    else:
                                        learning_path_desc = str(learning_path_info) if learning_path_info else "æ¨èå­¦ä¹ "
                                        learning_path_reasoning = "ç›¸å…³ç®—æ³•ç»ƒä¹ "

                                    fallback_problem = SimilarProblem(
                                        title=rec["title"],
                                        hybrid_score=float(rec.get("hybrid_score", 0.8)),
                                        embedding_score=float(rec.get("embedding_score", 0.7)),
                                        tag_score=float(rec.get("tag_score", 0.6)),
                                        shared_tags=[tag['display_name'] for tag in formatted_tags],
                                        learning_path=learning_path_desc,
                                        recommendation_reason=rec.get("recommendation_reason", "ç®—æ³•ç›¸ä¼¼æ€§æ¨è"),
                                        learning_path_explanation=learning_path_reasoning,
                                        recommendation_strength="æ¨èç³»ç»Ÿ",
                                        complete_info=None
                                    )
                                    similar_problems.append(fallback_problem)
                                except Exception as rec_error:
                                    logger.warning(f"å¤„ç†æ¨èç»“æœæ—¶å‡ºé”™: {rec_error}, æ¨èæ•°æ®: {rec}")
                                    continue
                            logger.info(f"åŸå§‹æ¨èç³»ç»Ÿè¡¥å……äº† {len(rec_result['recommendations'])} ä¸ªæ¨è")

            except Exception as e:
                logger.error(f"æ¨èç³»ç»Ÿè°ƒç”¨å¤±è´¥: {e}")
                import traceback
                logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

        # 3. å¦‚æœä»ç„¶æ²¡æœ‰è¶³å¤Ÿçš„ç›¸ä¼¼é¢˜ç›®ï¼Œæ·»åŠ LLMå¤‡ç”¨æ¨è
        if len(similar_problems) < 2:
            try:
                from app.services.enhanced_problem_service import EnhancedProblemService
                enhanced_service = EnhancedProblemService()
                fallback_recommendations = enhanced_service.get_fallback_recommendations(request.query)

                # å°†å¤‡ç”¨æ¨èè½¬æ¢ä¸ºç›¸ä¼¼é¢˜ç›®æ ¼å¼
                for i, rec in enumerate(fallback_recommendations[:3 - len(similar_problems)]):
                    fallback_problem = SimilarProblem(
                        title=f"æ™ºèƒ½æ¨è {i+1}",
                        hybrid_score=0.6,
                        embedding_score=0.0,
                        tag_score=0.0,
                        shared_tags=["æ™ºèƒ½åˆ†æ"],
                        learning_path=rec,
                        recommendation_reason="åŸºäºLLMæ™ºèƒ½åˆ†æç”Ÿæˆçš„æ¨è",
                        learning_path_explanation=rec,
                        recommendation_strength="LLMæ¨è",
                        complete_info=None
                    )
                    similar_problems.append(fallback_problem)
                logger.info(f"LLMå¤‡ç”¨æ¨èè¡¥å……äº† {len(fallback_recommendations)} ä¸ªæ¨è")
            except Exception as e:
                logger.error(f"LLMå¤‡ç”¨æ¨èå¤±è´¥: {e}")

        # 4. æœ€åçš„å¤‡ç”¨æ¨è - å¦‚æœæ‰€æœ‰æ¨èç³»ç»Ÿéƒ½å¤±è´¥ï¼Œæä¾›åŸºæœ¬æ¨è
        if len(similar_problems) == 0:
            logger.warning("æ‰€æœ‰æ¨èç³»ç»Ÿéƒ½å¤±è´¥ï¼Œä½¿ç”¨åŸºæœ¬å¤‡ç”¨æ¨è")
            basic_recommendations = [
                {
                    "title": "ä¸¤æ•°ä¹‹å’Œ",
                    "reason": "ç»å…¸å…¥é—¨é¢˜ç›®ï¼Œé€‚åˆç®—æ³•å­¦ä¹ ",
                    "tags": ["æ•°ç»„", "å“ˆå¸Œè¡¨"]
                },
                {
                    "title": "çˆ¬æ¥¼æ¢¯",
                    "reason": "åŠ¨æ€è§„åˆ’å…¥é—¨é¢˜ç›®",
                    "tags": ["åŠ¨æ€è§„åˆ’", "é€’æ¨"]
                },
                {
                    "title": "äºŒåˆ†æŸ¥æ‰¾",
                    "reason": "åŸºç¡€æœç´¢ç®—æ³•",
                    "tags": ["äºŒåˆ†æŸ¥æ‰¾", "æ•°ç»„"]
                }
            ]

            for i, rec in enumerate(basic_recommendations):
                basic_problem = SimilarProblem(
                    title=rec["title"],
                    hybrid_score=0.5,
                    embedding_score=0.0,
                    tag_score=0.0,
                    shared_tags=rec["tags"],
                    learning_path="åŸºç¡€ç®—æ³•å­¦ä¹ ",
                    recommendation_reason=rec["reason"],
                    learning_path_explanation="æ¨èçš„åŸºç¡€ç®—æ³•é¢˜ç›®",
                    recommendation_strength="åŸºç¡€æ¨è",
                    complete_info=None
                )
                similar_problems.append(basic_problem)
            logger.info(f"åŸºç¡€å¤‡ç”¨æ¨èæä¾›äº† {len(basic_recommendations)} ä¸ªæ¨è")
        
        # ç”Ÿæˆå›¾è°±æ•°æ®
        graph_data = await self._generate_graph_data(result)

        # è°ƒè¯•æ—¥å¿—
        logger.info(f"QAå“åº”æ„å»º - å›¾è°±æ•°æ®çŠ¶æ€:")
        logger.info(f"  graph_dataå­˜åœ¨: {graph_data is not None}")
        if graph_data:
            logger.info(f"  èŠ‚ç‚¹æ•°é‡: {len(graph_data.nodes) if graph_data.nodes else 0}")
            logger.info(f"  è¾¹æ•°é‡: {len(graph_data.edges) if graph_data.edges else 0}")
            logger.info(f"  ä¸­å¿ƒèŠ‚ç‚¹: {graph_data.center_node}")
            logger.info(f"  å¸ƒå±€ç±»å‹: {graph_data.layout_type}")

        # æ¸…ç†æ¨ç†è·¯å¾„ä¸­çš„æ— æ•ˆçŠ¶æ€å€¼
        reasoning_path = self._clean_reasoning_path(result.get("reasoning_path", []))

        qa_response = QAResponse(
            response_id=response_id,
            query=request.query,
            intent=result.get("intent", ""),
            entities=result.get("entities", []),
            concept_explanation=concept_explanation,
            example_problems=example_problems,
            similar_problems=similar_problems,
            recommendations_struct=result.get("recommendations_struct"),
            integrated_response=result.get("integrated_response", ""),
            graph_data=graph_data,
            reasoning_path=reasoning_path,
            status=ResponseStatus.SUCCESS,
            confidence=result.get("metadata", {}).get("confidence", 0.0),
            processing_time=processing_time,
            metadata=result.get("metadata", {})
        )

        # è°ƒè¯•ï¼šæ£€æŸ¥æœ€ç»ˆå“åº”ä¸­çš„graph_data
        logger.info(f"æœ€ç»ˆQAå“åº”ä¸­çš„graph_data: {qa_response.graph_data is not None}")

        return qa_response

    def _clean_reasoning_path(self, reasoning_path: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ¸…ç†æ¨ç†è·¯å¾„ä¸­çš„æ— æ•ˆçŠ¶æ€å€¼"""
        cleaned_path = []

        for step in reasoning_path:
            cleaned_step = step.copy()

            # ä¿®å¤æ— æ•ˆçš„çŠ¶æ€å€¼
            status = cleaned_step.get("status", "success")
            if status not in ["success", "error", "partial", "processing"]:
                # å°†æ— æ•ˆçŠ¶æ€æ˜ å°„åˆ°æœ‰æ•ˆçŠ¶æ€
                if status in ["failed", "failure"]:
                    cleaned_step["status"] = "error"
                elif status in ["completed", "complete", "done", "finished"]:
                    cleaned_step["status"] = "success"
                elif status in ["running", "active", "working"]:
                    cleaned_step["status"] = "processing"
                else:
                    # é»˜è®¤ä¸ºsuccess
                    cleaned_step["status"] = "success"

            cleaned_path.append(cleaned_step)

        return cleaned_path

    def _convert_to_problem_info(self, problem_data: Dict[str, Any]) -> ProblemInfo:
        """è½¬æ¢é¢˜ç›®ä¿¡æ¯"""
        if not problem_data:
            return None

        # å®‰å…¨è·å–å¹¶è½¬æ¢åˆ—è¡¨å­—æ®µ
        def safe_get_list(data, key):
            value = data.get(key, [])
            if isinstance(value, str):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºåˆ—è¡¨
                if value.strip() == "[]":
                    return []
                try:
                    import ast
                    return ast.literal_eval(value)
                except:
                    return [value] if value else []
            elif isinstance(value, list):
                return value
            else:
                return [str(value)] if value else []

        # å®‰å…¨è·å–å¹¶è½¬æ¢å­—å…¸åˆ—è¡¨å­—æ®µ
        def safe_get_dict_list(data, key):
            value = data.get(key, [])
            if isinstance(value, str):
                if value.strip() == "[]":
                    return []
                # å¦‚æœæ˜¯Neo4jèŠ‚ç‚¹å¯¹è±¡çš„å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œè½¬æ¢ä¸ºå­—å…¸
                if "<Node element_id=" in value:
                    return [{"content": "Neo4jèŠ‚ç‚¹å†…å®¹"}]
                try:
                    import ast
                    parsed = ast.literal_eval(value)
                    return parsed if isinstance(parsed, list) else [parsed]
                except:
                    return [{"content": str(value)}] if value else []
            elif isinstance(value, list):
                # æ¸…ç†åˆ—è¡¨ä¸­çš„æ¯ä¸ªå…ƒç´ 
                cleaned_list = []
                for item in value:
                    if isinstance(item, dict):
                        cleaned_list.append(item)
                    elif isinstance(item, str) and "<Node element_id=" in item:
                        cleaned_list.append({"content": "Neo4jèŠ‚ç‚¹å†…å®¹"})
                    else:
                        cleaned_list.append({"content": str(item)})
                return cleaned_list
            else:
                return [{"content": str(value)}] if value else []

        return ProblemInfo(
            id=str(problem_data.get("id", problem_data.get("title", "unknown"))),
            title=str(problem_data.get("title", "æœªçŸ¥é¢˜ç›®")),
            description=problem_data.get("description"),
            difficulty=problem_data.get("difficulty"),
            platform=problem_data.get("platform"),
            url=problem_data.get("url"),
            algorithm_tags=safe_get_list(problem_data, "algorithm_tags"),
            data_structure_tags=safe_get_list(problem_data, "data_structure_tags"),
            technique_tags=safe_get_list(problem_data, "technique_tags"),
            solutions=safe_get_dict_list(problem_data, "solutions"),
            code_implementations=safe_get_dict_list(problem_data, "code_implementations"),
            key_insights=safe_get_dict_list(problem_data, "key_insights"),
            step_by_step_explanation=safe_get_dict_list(problem_data, "step_by_step_explanation"),
            clickable=bool(problem_data.get("clickable", True))
        )

    def _deep_clean_objects(self, obj):
        """æ·±åº¦æ¸…ç†å¯¹è±¡ï¼Œç¡®ä¿æ‰€æœ‰åµŒå¥—å¯¹è±¡éƒ½è¢«æ­£ç¡®åºåˆ—åŒ–"""
        if obj is None:
            return None
        elif isinstance(obj, str):
            # æ£€æŸ¥æ˜¯å¦æ˜¯Neo4jèŠ‚ç‚¹å­—ç¬¦ä¸²
            if obj.startswith('<Node element_id='):
                # å°è¯•ä»Neo4jèŠ‚ç‚¹å­—ç¬¦ä¸²ä¸­æå–åç§°
                import re
                name_match = re.search(r"'name':\s*'([^']+)'", obj)
                if name_match:
                    return name_match.group(1)
                else:
                    return "Neo4jèŠ‚ç‚¹"
            return obj
        elif isinstance(obj, (int, float, bool)):
            return obj
        elif hasattr(obj, 'get') and hasattr(obj, 'labels'):
            # è¿™æ˜¯Neo4jèŠ‚ç‚¹å¯¹è±¡ï¼Œæå–å…³é”®ä¿¡æ¯
            return {
                'name': obj.get('name', ''),
                'title': obj.get('title', ''),
                'description': obj.get('description', ''),
                'category': obj.get('category', ''),
                'type': obj.get('type', '')
            }
        elif isinstance(obj, dict):
            cleaned = {}
            for key, value in obj.items():
                cleaned_value = self._deep_clean_objects(value)
                # ç¡®ä¿å€¼ä¸æ˜¯å¤æ‚å¯¹è±¡
                if isinstance(cleaned_value, (dict, list)) and cleaned_value:
                    cleaned[key] = cleaned_value
                elif cleaned_value is not None:
                    cleaned[key] = str(cleaned_value) if not isinstance(cleaned_value, (str, int, float, bool)) else cleaned_value
            return cleaned
        elif isinstance(obj, list):
            cleaned = []
            for item in obj:
                cleaned_item = self._deep_clean_objects(item)
                if cleaned_item is not None:
                    cleaned.append(cleaned_item)
            return cleaned
        else:
            # æ£€æŸ¥æ˜¯å¦æ˜¯Neo4jèŠ‚ç‚¹å¯¹è±¡
            obj_str = str(obj)
            if "<Node element_id=" in obj_str:
                # è§£æNeo4jèŠ‚ç‚¹å¹¶è½¬æ¢ä¸ºç®€æ´æ ¼å¼
                logger.info(f"å‘ç°Neo4jèŠ‚ç‚¹å¯¹è±¡: {obj_str[:200]}...")
                return self._format_neo4j_node(obj_str)
            # å¯¹äºå…¶ä»–ç±»å‹ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
            return str(obj)

    def _format_neo4j_node(self, node_str: str) -> str:
        """å°†Neo4jèŠ‚ç‚¹å­—ç¬¦ä¸²è½¬æ¢ä¸ºç®€æ´çš„æ˜¾ç¤ºæ ¼å¼"""
        try:
            import re

            # æå–èŠ‚ç‚¹å±æ€§
            properties_match = re.search(r"properties=\{([^}]+)\}", node_str)
            if not properties_match:
                return "ç›¸å…³å†…å®¹"

            properties_str = properties_match.group(1)

            # è§£æå…³é”®å±æ€§
            name_match = re.search(r"'name':\s*'([^']+)'", properties_str)
            title_match = re.search(r"'title':\s*'([^']+)'", properties_str)
            desc_match = re.search(r"'description':\s*'([^']+)'", properties_str)
            category_match = re.search(r"'category':\s*'([^']+)'", properties_str)
            difficulty_match = re.search(r"'difficulty':\s*'([^']+)'", properties_str)

            # è·å–åç§°ï¼ˆä¼˜å…ˆtitleï¼Œç„¶ånameï¼‰
            name = (title_match.group(1) if title_match else
                   name_match.group(1) if name_match else "ç›¸å…³å†…å®¹")

            # æ„å»ºç®€æ´çš„æ˜¾ç¤ºæ ¼å¼
            result_parts = [f"**{name}**"]

            # æ·»åŠ åˆ†ç±»æ ‡ç­¾
            if category_match:
                result_parts.append(f"`{category_match.group(1)}`")

            # æ·»åŠ éš¾åº¦æ ‡ç­¾
            if difficulty_match:
                difficulty = difficulty_match.group(1)
                difficulty_emoji = {"ç®€å•": "ğŸŸ¢", "ä¸­ç­‰": "ğŸŸ¡", "å›°éš¾": "ğŸ”´"}.get(difficulty, "")
                result_parts.append(f"{difficulty_emoji}`{difficulty}`")

            # æ·»åŠ æè¿°
            if desc_match:
                description = desc_match.group(1)
                if len(description) > 50:
                    description = description[:50] + "..."
                result_parts.append(f"- {description}")

            return " ".join(result_parts)

        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–Neo4jèŠ‚ç‚¹å¤±è´¥: {e}")
            return "ç›¸å…³å†…å®¹"

    def _extract_clickable_concepts(self, concept_data: Dict[str, Any]) -> List[str]:
        """æå–å¯ç‚¹å‡»çš„æ¦‚å¿µ"""
        clickable = []
        
        # ä»å‰ç½®æ¦‚å¿µä¸­æå–
        prerequisites = concept_data.get("learning_progression", {}).get("prerequisites", [])
        if isinstance(prerequisites, list):
            clickable.extend(prerequisites)
        
        # ä»åç»­æ¦‚å¿µä¸­æå–
        next_concepts = concept_data.get("learning_progression", {}).get("next_concepts", [])
        if isinstance(next_concepts, list):
            clickable.extend(next_concepts)
        
        # ä»ç›¸ä¼¼æ¦‚å¿µä¸­æå–
        similar_concepts = concept_data.get("similar_concepts", [])
        if isinstance(similar_concepts, list):
            clickable.extend(similar_concepts)
        
        return list(set(clickable))  # å»é‡
    
    async def _generate_graph_data(self, result: Dict[str, Any]) -> Optional[GraphData]:
        """ç”ŸæˆçŸ¥è¯†å›¾è°±å¯è§†åŒ–æ•°æ® - å®Œæ•´Neo4jç‰ˆæœ¬"""
        try:
            from app.core.deps import get_neo4j_api

            # è·å–Neo4j APIå®ä¾‹
            neo4j_api = get_neo4j_api()
            if not neo4j_api:
                logger.warning("Neo4j APIä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆå›¾è°±æ•°æ®")
                return None

            entities = result.get("entities", [])
            if not entities:
                logger.info("æ²¡æœ‰è¯†åˆ«åˆ°å®ä½“ï¼Œè·³è¿‡å›¾è°±ç”Ÿæˆ")
                return None

            # é€‰æ‹©ä¸»è¦å®ä½“ä½œä¸ºä¸­å¿ƒèŠ‚ç‚¹
            center_entity = entities[0]
            logger.info(f"ä¸ºå®ä½“ '{center_entity}' ç”ŸæˆçŸ¥è¯†å›¾è°±")

            # ä½¿ç”¨å®Œæ•´çš„Neo4jå›¾è°±æŸ¥è¯¢
            graph_data = await self._query_neo4j_graph_data(neo4j_api, center_entity)

            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„èŠ‚ç‚¹å’Œè¾¹æ¥æ˜¾ç¤ºå›¾è°±
            if not graph_data or not graph_data.nodes or len(graph_data.nodes) <= 1:
                logger.info(f"å®ä½“ '{center_entity}' æ²¡æœ‰ç›¸è¿çš„èŠ‚ç‚¹ï¼Œè·³è¿‡å›¾è°±æ˜¾ç¤º")
                return None

            # æ£€æŸ¥æ˜¯å¦æœ‰è¾¹è¿æ¥
            if not graph_data.edges or len(graph_data.edges) == 0:
                logger.info(f"å®ä½“ '{center_entity}' æ²¡æœ‰å…³ç³»è¾¹ï¼Œè·³è¿‡å›¾è°±æ˜¾ç¤º")
                return None

            logger.info(f"æˆåŠŸç”ŸæˆçŸ¥è¯†å›¾è°±: {len(graph_data.nodes)}ä¸ªèŠ‚ç‚¹, {len(graph_data.edges)}æ¡è¾¹")

            # å¢å¼ºå›¾è°±æ•°æ®ï¼Œæ·»åŠ æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯
            enhanced_graph_data = self._enhance_graph_data_with_context(graph_data, result)

            return enhanced_graph_data

        except Exception as e:
            logger.error(f"ç”Ÿæˆå›¾è°±æ•°æ®å¤±è´¥: {e}")
            import traceback
            logger.debug(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return None

    async def _query_neo4j_graph_data(self, neo4j_api, center_entity: str) -> Optional[GraphData]:
        """æŸ¥è¯¢Neo4jå›¾è°±æ•°æ®"""
        try:
            # é¦–å…ˆæ£€æŸ¥å®ä½“æ˜¯å¦å­˜åœ¨äºNeo4jä¸­
            node_info = await self._get_entity_info(neo4j_api, center_entity)
            if not node_info:
                logger.info(f"å®ä½“ '{center_entity}' åœ¨Neo4jä¸­ä¸å­˜åœ¨")
                return None

            entity_type = node_info.get("type", "Unknown")
            logger.info(f"å®ä½“ç±»å‹: {entity_type}")

            # æ ¹æ®å®ä½“ç±»å‹æ„å»ºä¸åŒçš„æŸ¥è¯¢
            if entity_type in ["Algorithm", "ç®—æ³•"]:
                return await self._query_algorithm_graph(neo4j_api, center_entity)
            elif entity_type in ["Problem", "é¢˜ç›®"]:
                return await self._query_problem_graph(neo4j_api, center_entity)
            elif entity_type in ["DataStructure", "æ•°æ®ç»“æ„"]:
                return await self._query_datastructure_graph(neo4j_api, center_entity)
            else:
                return await self._query_general_graph(neo4j_api, center_entity)

        except Exception as e:
            logger.error(f"æŸ¥è¯¢Neo4jå›¾è°±æ•°æ®å¤±è´¥: {e}")
            return None

    async def _get_entity_info(self, neo4j_api, entity_name: str) -> Optional[Dict]:
        """è·å–å®ä½“ä¿¡æ¯"""
        try:
            # å°è¯•å¤šç§æŸ¥è¯¢æ–¹å¼
            queries = [
                "MATCH (n) WHERE n.name = $name RETURN n LIMIT 1",
                "MATCH (n) WHERE n.title = $name RETURN n LIMIT 1",
                "MATCH (n) WHERE toLower(n.name) = toLower($name) RETURN n LIMIT 1",
                "MATCH (n) WHERE toLower(n.title) = toLower($name) RETURN n LIMIT 1"
            ]

            for query in queries:
                results = neo4j_api.run_query(query, {"name": entity_name})
                if results:
                    node = results[0].get('n')
                    if node:
                        # æå–èŠ‚ç‚¹ä¿¡æ¯
                        node_info = {
                            "name": getattr(node, 'get', lambda x, d: d)('name', entity_name),
                            "title": getattr(node, 'get', lambda x, d: d)('title', ''),
                            "type": "Unknown"
                        }

                        # ä»æ ‡ç­¾ç¡®å®šç±»å‹
                        if hasattr(node, 'labels'):
                            labels = list(node.labels)
                            if labels:
                                node_info["type"] = labels[0]

                        return node_info

            return None

        except Exception as e:
            logger.error(f"è·å–å®ä½“ä¿¡æ¯å¤±è´¥: {e}")
            return None

    async def _query_algorithm_graph(self, neo4j_api, algorithm_name: str) -> Optional[GraphData]:
        """æŸ¥è¯¢ç®—æ³•ç›¸å…³çš„å›¾è°±"""
        try:
            cypher = """
            MATCH (a:Algorithm)
            WHERE a.name = $algorithm_name OR toLower(a.name) = toLower($algorithm_name)
            OPTIONAL MATCH (p:Problem)-[r1:USES_ALGORITHM]->(a)
            OPTIONAL MATCH (a)-[r2:RELATED_TO]->(ra:Algorithm)
            OPTIONAL MATCH (a)-[r3:REQUIRES_DATA_STRUCTURE]->(ds:DataStructure)
            OPTIONAL MATCH (a)-[r4:USES_TECHNIQUE]->(t:Technique)

            RETURN a as center_node,
                   collect(DISTINCT {node: p, rel: type(r1), type: 'Problem'}) as problems,
                   collect(DISTINCT {node: ra, rel: type(r2), type: 'Algorithm'}) as related_algorithms,
                   collect(DISTINCT {node: ds, rel: type(r3), type: 'DataStructure'}) as data_structures,
                   collect(DISTINCT {node: t, rel: type(r4), type: 'Technique'}) as techniques
            LIMIT 1
            """

            results = neo4j_api.run_query(cypher, {"algorithm_name": algorithm_name})
            return self._convert_neo4j_results_to_graph_data(results, algorithm_name)

        except Exception as e:
            logger.error(f"æŸ¥è¯¢ç®—æ³•å›¾è°±å¤±è´¥: {e}")
            return None

    async def _query_problem_graph(self, neo4j_api, problem_title: str) -> Optional[GraphData]:
        """æŸ¥è¯¢é¢˜ç›®ç›¸å…³çš„å›¾è°±"""
        try:
            cypher = """
            MATCH (p:Problem)
            WHERE p.title = $problem_title OR toLower(p.title) = toLower($problem_title)
            OPTIONAL MATCH (p)-[r1:USES_ALGORITHM]->(a:Algorithm)
            OPTIONAL MATCH (p)-[r2:USES_DATA_STRUCTURE]->(ds:DataStructure)
            OPTIONAL MATCH (p)-[r3:USES_TECHNIQUE]->(t:Technique)
            OPTIONAL MATCH (p)-[r4:SIMILAR_TO]->(sp:Problem)

            RETURN p as center_node,
                   collect(DISTINCT {node: a, rel: type(r1), type: 'Algorithm'}) as algorithms,
                   collect(DISTINCT {node: ds, rel: type(r2), type: 'DataStructure'}) as data_structures,
                   collect(DISTINCT {node: t, rel: type(r3), type: 'Technique'}) as techniques,
                   collect(DISTINCT {node: sp, rel: type(r4), type: 'Problem'}) as similar_problems
            LIMIT 1
            """

            results = neo4j_api.run_query(cypher, {"problem_title": problem_title})
            return self._convert_neo4j_results_to_graph_data(results, problem_title)

        except Exception as e:
            logger.error(f"æŸ¥è¯¢é¢˜ç›®å›¾è°±å¤±è´¥: {e}")
            return None

    async def _query_datastructure_graph(self, neo4j_api, ds_name: str) -> Optional[GraphData]:
        """æŸ¥è¯¢æ•°æ®ç»“æ„ç›¸å…³çš„å›¾è°±"""
        try:
            cypher = """
            MATCH (ds:DataStructure)
            WHERE ds.name = $ds_name OR toLower(ds.name) = toLower($ds_name)
            OPTIONAL MATCH (p:Problem)-[r1:USES_DATA_STRUCTURE]->(ds)
            OPTIONAL MATCH (a:Algorithm)-[r2:REQUIRES_DATA_STRUCTURE]->(ds)
            OPTIONAL MATCH (ds)-[r3:RELATED_TO]->(rds:DataStructure)

            RETURN ds as center_node,
                   collect(DISTINCT {node: p, rel: type(r1), type: 'Problem'}) as problems,
                   collect(DISTINCT {node: a, rel: type(r2), type: 'Algorithm'}) as algorithms,
                   collect(DISTINCT {node: rds, rel: type(r3), type: 'DataStructure'}) as related_ds
            LIMIT 1
            """

            results = neo4j_api.run_query(cypher, {"ds_name": ds_name})
            return self._convert_neo4j_results_to_graph_data(results, ds_name)

        except Exception as e:
            logger.error(f"æŸ¥è¯¢æ•°æ®ç»“æ„å›¾è°±å¤±è´¥: {e}")
            return None

    async def _query_general_graph(self, neo4j_api, entity_name: str) -> Optional[GraphData]:
        """æŸ¥è¯¢é€šç”¨å®ä½“çš„å›¾è°±"""
        try:
            cypher = """
            MATCH (center)
            WHERE center.name = $entity_name OR center.title = $entity_name
            OPTIONAL MATCH (center)-[r]-(connected)
            WHERE connected IS NOT NULL

            RETURN center as center_node,
                   collect(DISTINCT {node: connected, rel: type(r), type: labels(connected)[0]}) as connections
            LIMIT 1
            """

            results = neo4j_api.run_query(cypher, {"entity_name": entity_name})
            return self._convert_neo4j_results_to_graph_data(results, entity_name)

        except Exception as e:
            logger.error(f"æŸ¥è¯¢é€šç”¨å›¾è°±å¤±è´¥: {e}")
            return None

    def _convert_neo4j_results_to_graph_data(self, results: List[Dict], center_entity: str) -> Optional[GraphData]:
        """å°†Neo4jæŸ¥è¯¢ç»“æœè½¬æ¢ä¸ºå›¾è°±æ•°æ®"""
        try:
            if not results:
                logger.info(f"Neo4jæŸ¥è¯¢æ— ç»“æœ: {center_entity}")
                return None

            result = results[0]
            center_node = result.get('center_node')

            if not center_node:
                logger.info(f"æœªæ‰¾åˆ°ä¸­å¿ƒèŠ‚ç‚¹: {center_entity}")
                return None

            nodes = []
            edges = []

            # æ·»åŠ ä¸­å¿ƒèŠ‚ç‚¹
            center_id = self._create_node_id_from_neo4j(center_node)
            center_label = self._extract_node_label(center_node, center_entity)
            center_type = self._extract_node_type(center_node)

            nodes.append(GraphNode(
                id=center_id,
                label=center_label,
                type=center_type,
                properties={"is_center": True},
                clickable=True
            ))

            # å¤„ç†è¿æ¥çš„èŠ‚ç‚¹
            for key, connections in result.items():
                if key == 'center_node' or not connections:
                    continue

                # é™åˆ¶æ¯ç§ç±»å‹çš„èŠ‚ç‚¹æ•°é‡
                limited_connections = connections[:10] if isinstance(connections, list) else []

                for connection in limited_connections:
                    if not isinstance(connection, dict) or 'node' not in connection:
                        continue

                    connected_node = connection['node']
                    if not connected_node:
                        continue

                    # åˆ›å»ºè¿æ¥èŠ‚ç‚¹
                    connected_id = self._create_node_id_from_neo4j(connected_node)
                    connected_label = self._extract_node_label(connected_node)
                    connected_type = connection.get('type', self._extract_node_type(connected_node))

                    # é¿å…é‡å¤èŠ‚ç‚¹
                    if not any(node.id == connected_id for node in nodes):
                        nodes.append(GraphNode(
                            id=connected_id,
                            label=connected_label,
                            type=connected_type,
                            properties={},
                            clickable=True
                        ))

                    # åˆ›å»ºè¾¹
                    relationship = connection.get('rel', 'RELATED_TO')
                    edges.append(GraphEdge(
                        source=center_id,
                        target=connected_id,
                        relationship=relationship,
                        properties={}
                    ))

            if len(nodes) <= 1:
                logger.info(f"å®ä½“ '{center_entity}' æ²¡æœ‰è¿æ¥çš„èŠ‚ç‚¹")
                return None

            logger.info(f"è½¬æ¢Neo4jç»“æœ: {len(nodes)}ä¸ªèŠ‚ç‚¹, {len(edges)}æ¡è¾¹")

            return GraphData(
                nodes=nodes,
                edges=edges,
                center_node=center_id,
                layout_type="force"
            )

        except Exception as e:
            logger.error(f"è½¬æ¢Neo4jç»“æœå¤±è´¥: {e}")
            return None

    def _create_node_id_from_neo4j(self, node) -> str:
        """ä»Neo4jèŠ‚ç‚¹åˆ›å»ºID"""
        try:
            if hasattr(node, 'element_id'):
                return f"neo4j_{node.element_id}"
            elif hasattr(node, 'id'):
                return f"neo4j_{node.id}"
            else:
                # ä½¿ç”¨èŠ‚ç‚¹å±æ€§åˆ›å»ºID
                name = getattr(node, 'get', lambda x, d: d)('name', '')
                title = getattr(node, 'get', lambda x, d: d)('title', '')
                identifier = name or title or str(hash(str(node)))
                return f"neo4j_{identifier}"
        except:
            return f"neo4j_{hash(str(node))}"

    def _extract_node_label(self, node, default: str = "Unknown") -> str:
        """æå–èŠ‚ç‚¹æ ‡ç­¾"""
        try:
            if hasattr(node, 'get'):
                return node.get('name', node.get('title', default))
            elif isinstance(node, dict):
                return node.get('name', node.get('title', default))
            else:
                return str(node)
        except:
            return default

    def _extract_node_type(self, node) -> str:
        """æå–èŠ‚ç‚¹ç±»å‹"""
        try:
            if hasattr(node, 'labels'):
                labels = list(node.labels)
                return labels[0] if labels else "Unknown"
            elif isinstance(node, dict) and 'labels' in node:
                labels = node['labels']
                return labels[0] if labels else "Unknown"
            else:
                return "Unknown"
        except:
            return "Unknown"

    def _create_simple_graph_from_results(self, result: Dict[str, Any], center_entity: str) -> Optional[GraphData]:
        """åŸºäºQAç»“æœåˆ›å»ºç®€åŒ–çš„å›¾è°±æ•°æ®"""
        try:
            nodes = []
            edges = []

            # æ·»åŠ ä¸­å¿ƒèŠ‚ç‚¹
            center_id = f"center_{center_entity}"
            nodes.append(GraphNode(
                id=center_id,
                label=center_entity,
                type="Concept",
                properties={"is_center": True},
                clickable=True
            ))

            # ä»ç›¸ä¼¼é¢˜ç›®ä¸­æ·»åŠ èŠ‚ç‚¹
            similar_problems = result.get("similar_problems", [])
            for i, problem in enumerate(similar_problems[:5]):  # é™åˆ¶æ•°é‡
                if isinstance(problem, dict):
                    title = problem.get("title", f"é¢˜ç›®{i+1}")
                    problem_id = f"problem_{i}"

                    nodes.append(GraphNode(
                        id=problem_id,
                        label=title,
                        type="Problem",
                        properties={
                            "score": problem.get("hybrid_score", 0.0),
                            "difficulty": problem.get("difficulty", "æœªçŸ¥")
                        },
                        clickable=True
                    ))

                    # æ·»åŠ è¾¹
                    edges.append(GraphEdge(
                        source=center_id,
                        target=problem_id,
                        relationship="RELATED_TO",
                        properties={"score": problem.get("hybrid_score", 0.0)}
                    ))

            # ä»ç¤ºä¾‹é¢˜ç›®ä¸­æ·»åŠ èŠ‚ç‚¹
            example_problems = result.get("example_problems", [])
            for i, problem in enumerate(example_problems[:3]):  # é™åˆ¶æ•°é‡
                if isinstance(problem, dict):
                    title = problem.get("title", f"ç¤ºä¾‹{i+1}")
                    example_id = f"example_{i}"

                    nodes.append(GraphNode(
                        id=example_id,
                        label=title,
                        type="Example",
                        properties={
                            "difficulty": problem.get("difficulty", "æœªçŸ¥"),
                            "platform": problem.get("platform", "æœªçŸ¥")
                        },
                        clickable=True
                    ))

                    # æ·»åŠ è¾¹
                    edges.append(GraphEdge(
                        source=center_id,
                        target=example_id,
                        relationship="EXAMPLE_OF",
                        properties={}
                    ))

            # ä»æ¦‚å¿µè§£é‡Šä¸­æ·»åŠ ç›¸å…³æ¦‚å¿µèŠ‚ç‚¹
            concept_explanation = result.get("concept_explanation", {})
            if isinstance(concept_explanation, dict):
                core_principles = concept_explanation.get("core_principles", [])
                for i, principle in enumerate(core_principles[:3]):  # é™åˆ¶æ•°é‡
                    if isinstance(principle, str):
                        principle_id = f"principle_{i}"

                        nodes.append(GraphNode(
                            id=principle_id,
                            label=principle,
                            type="Principle",
                            properties={},
                            clickable=True
                        ))

                        # æ·»åŠ è¾¹
                        edges.append(GraphEdge(
                            source=center_id,
                            target=principle_id,
                            relationship="HAS_PRINCIPLE",
                            properties={}
                        ))

            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„èŠ‚ç‚¹
            if len(nodes) <= 1:
                logger.info(f"æ²¡æœ‰è¶³å¤Ÿçš„ç›¸å…³èŠ‚ç‚¹æ¥åˆ›å»ºå›¾è°±")
                return None

            return GraphData(
                nodes=nodes,
                edges=edges,
                center_node=center_id,
                layout_type="force"
            )

        except Exception as e:
            logger.error(f"åˆ›å»ºç®€åŒ–å›¾è°±æ•°æ®å¤±è´¥: {e}")
            return None

    def _query_simple_graph_data(self, neo4j_api, center_entity: str) -> Optional[GraphData]:
        """æŸ¥è¯¢ç®€åŒ–çš„å›¾è°±æ•°æ®"""
        try:
            # æ„å»ºç®€å•çš„CypheræŸ¥è¯¢ï¼ŒæŸ¥æ‰¾ä¸å®ä½“ç›¸å…³çš„èŠ‚ç‚¹
            cypher = """
            MATCH (center)
            WHERE center.name = $entity_name OR center.title = $entity_name
            OPTIONAL MATCH (center)-[r]-(connected)
            WHERE connected IS NOT NULL
            RETURN center,
                   collect(DISTINCT {node: connected, rel: r, rel_type: type(r)}) as connections
            LIMIT 1
            """

            params = {"entity_name": center_entity}
            results = neo4j_api.run_query(cypher, params)

            if not results:
                logger.info(f"æœªæ‰¾åˆ°å®ä½“ '{center_entity}' çš„å›¾è°±æ•°æ®")
                return None

            return self._convert_simple_results_to_graph_data(results, center_entity)

        except Exception as e:
            logger.error(f"æŸ¥è¯¢ç®€åŒ–å›¾è°±æ•°æ®å¤±è´¥: {e}")
            return None

    def _convert_simple_results_to_graph_data(self, results: List[Dict], center_entity: str) -> Optional[GraphData]:
        """å°†ç®€åŒ–çš„æŸ¥è¯¢ç»“æœè½¬æ¢ä¸ºå›¾è°±æ•°æ®"""
        try:
            if not results:
                return None

            result = results[0]
            center_node = result.get('center')
            connections = result.get('connections', [])

            if not center_node:
                return None

            nodes = []
            edges = []

            # æ·»åŠ ä¸­å¿ƒèŠ‚ç‚¹
            center_id = f"center_{center_entity}"
            center_label = getattr(center_node, 'get', lambda x, d: d)('name', center_entity) or center_entity
            center_type = "Concept"

            # å°è¯•ä»èŠ‚ç‚¹æ ‡ç­¾ç¡®å®šç±»å‹
            if hasattr(center_node, 'labels'):
                labels = list(center_node.labels)
                if labels:
                    center_type = labels[0]

            nodes.append(GraphNode(
                id=center_id,
                label=center_label,
                type=center_type,
                properties={"is_center": True},
                clickable=True
            ))

            # æ·»åŠ è¿æ¥çš„èŠ‚ç‚¹å’Œè¾¹
            for i, connection in enumerate(connections[:15]):  # é™åˆ¶è¿æ¥æ•°é‡
                if not isinstance(connection, dict) or 'node' not in connection:
                    continue

                connected_node = connection['node']
                relationship = connection.get('rel')
                rel_type = connection.get('rel_type', 'RELATED_TO')

                if not connected_node:
                    continue

                # åˆ›å»ºè¿æ¥èŠ‚ç‚¹
                connected_id = f"connected_{i}"
                connected_label = getattr(connected_node, 'get', lambda x, d: d)('name', f'Node_{i}') or \
                                getattr(connected_node, 'get', lambda x, d: d)('title', f'Node_{i}') or f'Node_{i}'
                connected_type = "Unknown"

                # å°è¯•ä»èŠ‚ç‚¹æ ‡ç­¾ç¡®å®šç±»å‹
                if hasattr(connected_node, 'labels'):
                    labels = list(connected_node.labels)
                    if labels:
                        connected_type = labels[0]

                nodes.append(GraphNode(
                    id=connected_id,
                    label=connected_label,
                    type=connected_type,
                    properties={},
                    clickable=True
                ))

                # åˆ›å»ºè¾¹
                edges.append(GraphEdge(
                    source=center_id,
                    target=connected_id,
                    relationship=rel_type,
                    properties={}
                ))

            if len(nodes) <= 1 or len(edges) == 0:
                logger.info(f"å®ä½“ '{center_entity}' æ²¡æœ‰è¶³å¤Ÿçš„è¿æ¥èŠ‚ç‚¹")
                return None

            return GraphData(
                nodes=nodes,
                edges=edges,
                center_node=center_id,
                layout_type="force"
            )

        except Exception as e:
            logger.error(f"è½¬æ¢ç®€åŒ–å›¾è°±æ•°æ®å¤±è´¥: {e}")
            return None

    def _enhance_graph_data_with_context(self, graph_data: GraphData, result: Dict[str, Any]) -> GraphData:
        """å¢å¼ºå›¾è°±æ•°æ®ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        try:
            # è·å–ç›¸ä¼¼é¢˜ç›®ä¿¡æ¯ï¼Œç”¨äºå¢å¼ºèŠ‚ç‚¹å±æ€§
            similar_problems = result.get("similar_problems", [])
            similar_titles = {problem.get("title", "") for problem in similar_problems if isinstance(problem, dict)}

            # å¢å¼ºèŠ‚ç‚¹ä¿¡æ¯
            enhanced_nodes = []
            for node in graph_data.nodes:
                enhanced_node = GraphNode(
                    id=node.id,
                    label=node.label,
                    type=node.type,
                    properties={
                        **node.properties,
                        "from_qa_context": True,  # æ ‡è®°è¿™æ˜¯æ¥è‡ªQAä¸Šä¸‹æ–‡çš„å›¾è°±
                        "is_recommended": node.label in similar_titles,  # æ ‡è®°æ˜¯å¦åœ¨æ¨èåˆ—è¡¨ä¸­
                    },
                    clickable=node.clickable
                )
                enhanced_nodes.append(enhanced_node)

            # å¢å¼ºè¾¹ä¿¡æ¯
            enhanced_edges = []
            for edge in graph_data.edges:
                enhanced_edge = GraphEdge(
                    source=edge.source,
                    target=edge.target,
                    relationship=edge.relationship,
                    properties={
                        **edge.properties,
                        "from_qa_context": True,  # æ ‡è®°è¿™æ˜¯æ¥è‡ªQAä¸Šä¸‹æ–‡çš„å›¾è°±
                    }
                )
                enhanced_edges.append(enhanced_edge)

            return GraphData(
                nodes=enhanced_nodes,
                edges=enhanced_edges,
                center_node=graph_data.center_node,
                layout_type=graph_data.layout_type
            )

        except Exception as e:
            logger.error(f"å¢å¼ºå›¾è°±æ•°æ®å¤±è´¥: {e}")
            # å¦‚æœå¢å¼ºå¤±è´¥ï¼Œè¿”å›åŸå§‹æ•°æ®
            return graph_data
