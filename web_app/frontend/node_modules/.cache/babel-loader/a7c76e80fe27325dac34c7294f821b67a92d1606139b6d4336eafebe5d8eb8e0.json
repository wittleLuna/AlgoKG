{"ast":null,"code":"/**\n * @import {\n *   Construct,\n *   Resolver,\n *   State,\n *   TokenizeContext,\n *   Tokenizer,\n *   Token\n * } from 'micromark-util-types'\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { subtokenize } from 'micromark-util-subtokenize';\n/**\n * No name because it must not be turned off.\n * @type {Construct}\n */\nexport const content = {\n  resolve: resolveContent,\n  tokenize: tokenizeContent\n};\n\n/** @type {Construct} */\nconst continuationConstruct = {\n  partial: true,\n  tokenize: tokenizeContinuation\n};\n\n/**\n * Content is transparent: itâ€™s parsed right now. That way, definitions are also\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\n *\n * @type {Resolver}\n */\nfunction resolveContent(events) {\n  subtokenize(events);\n  return events;\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token | undefined} */\n  let previous;\n  return chunkStart;\n\n  /**\n   * Before a content chunk.\n   *\n   * ```markdown\n   * > | abc\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function chunkStart(code) {\n    effects.enter(\"content\");\n    previous = effects.enter(\"chunkContent\", {\n      contentType: \"content\"\n    });\n    return chunkInside(code);\n  }\n\n  /**\n   * In a content chunk.\n   *\n   * ```markdown\n   * > | abc\n   *     ^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function chunkInside(code) {\n    if (code === null) {\n      return contentEnd(code);\n    }\n\n    // To do: in `markdown-rs`, each line is parsed on its own, and everything\n    // is stitched together resolving.\n    if (markdownLineEnding(code)) {\n      return effects.check(continuationConstruct, contentContinue, contentEnd)(code);\n    }\n\n    // Data.\n    effects.consume(code);\n    return chunkInside;\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function contentEnd(code) {\n    effects.exit(\"chunkContent\");\n    effects.exit(\"content\");\n    return ok(code);\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function contentContinue(code) {\n    effects.consume(code);\n    effects.exit(\"chunkContent\");\n    previous.next = effects.enter(\"chunkContent\", {\n      contentType: \"content\",\n      previous\n    });\n    previous = previous.next;\n    return chunkInside;\n  }\n}\n\n/**\n * @this {TokenizeContext}\n *   Context.\n * @type {Tokenizer}\n */\nfunction tokenizeContinuation(effects, ok, nok) {\n  const self = this;\n  return startLookahead;\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function startLookahead(code) {\n    effects.exit(\"chunkContent\");\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    return factorySpace(effects, prefixed, \"linePrefix\");\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code);\n    }\n\n    // Always populated by defaults.\n\n    const tail = self.events[self.events.length - 1];\n    if (!self.parser.constructs.disable.null.includes('codeIndented') && tail && tail[1].type === \"linePrefix\" && tail[2].sliceSerialize(tail[1], true).length >= 4) {\n      return ok(code);\n    }\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code);\n  }\n}","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}